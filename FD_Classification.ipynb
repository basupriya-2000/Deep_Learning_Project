{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8441ba02",
   "metadata": {
    "id": "8441ba02",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2 as cv\n",
    "# import seaborn as sns\n",
    "import pandas as pd\n",
    "from skimage.filters import sobel\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.measure import shannon_entropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "yPNlezQe-wfU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPNlezQe-wfU",
    "outputId": "810832d8-a4ef-4a74-8e09-4e09a37fded3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = \"dataset.zip\"\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "naylC-4LXtt7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "naylC-4LXtt7",
    "outputId": "aad4f6fb-eb6d-48b6-9aaa-704747655962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = \"datatest.zip\"\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03c781e1",
   "metadata": {
    "id": "03c781e1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fb6b4a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "3fb6b4a7",
    "outputId": "13a47c49-b813-4ca3-d0e0-344826c332d3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Energy_0</th>\n",
       "      <th>Corr_0</th>\n",
       "      <th>Homogen_0</th>\n",
       "      <th>Contrast_0</th>\n",
       "      <th>ASM_0</th>\n",
       "      <th>Energy_45</th>\n",
       "      <th>Corr_45</th>\n",
       "      <th>Homogen_45</th>\n",
       "      <th>Contrast_45</th>\n",
       "      <th>...</th>\n",
       "      <th>Homogen_90</th>\n",
       "      <th>Contrast_90</th>\n",
       "      <th>ASM_90</th>\n",
       "      <th>Energy_135</th>\n",
       "      <th>Corr_135</th>\n",
       "      <th>Homogen_135</th>\n",
       "      <th>Contrast_135</th>\n",
       "      <th>ASM_135</th>\n",
       "      <th>output</th>\n",
       "      <th>filenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.360166</td>\n",
       "      <td>0.849100</td>\n",
       "      <td>0.715262</td>\n",
       "      <td>400.557698</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>0.352685</td>\n",
       "      <td>0.830636</td>\n",
       "      <td>0.695192</td>\n",
       "      <td>449.911262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697137</td>\n",
       "      <td>444.862077</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>0.371847</td>\n",
       "      <td>0.867505</td>\n",
       "      <td>0.744380</td>\n",
       "      <td>352.059009</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>0</td>\n",
       "      <td>dataset\\0\\fish_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.400987</td>\n",
       "      <td>0.812333</td>\n",
       "      <td>0.749640</td>\n",
       "      <td>407.428869</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>0.408181</td>\n",
       "      <td>0.835459</td>\n",
       "      <td>0.768635</td>\n",
       "      <td>358.929444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721557</td>\n",
       "      <td>478.110919</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>0.392616</td>\n",
       "      <td>0.782994</td>\n",
       "      <td>0.729269</td>\n",
       "      <td>473.488716</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>0</td>\n",
       "      <td>dataset\\0\\fish_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.376491</td>\n",
       "      <td>0.877119</td>\n",
       "      <td>0.798621</td>\n",
       "      <td>690.161206</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0.378780</td>\n",
       "      <td>0.881331</td>\n",
       "      <td>0.804157</td>\n",
       "      <td>665.580926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821744</td>\n",
       "      <td>582.173172</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0.374711</td>\n",
       "      <td>0.873295</td>\n",
       "      <td>0.793183</td>\n",
       "      <td>711.160952</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0</td>\n",
       "      <td>dataset\\0\\fish_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.348277</td>\n",
       "      <td>0.832274</td>\n",
       "      <td>0.694796</td>\n",
       "      <td>652.404336</td>\n",
       "      <td>0.121297</td>\n",
       "      <td>0.349204</td>\n",
       "      <td>0.834127</td>\n",
       "      <td>0.699276</td>\n",
       "      <td>647.042470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707651</td>\n",
       "      <td>618.055012</td>\n",
       "      <td>0.121297</td>\n",
       "      <td>0.360706</td>\n",
       "      <td>0.865813</td>\n",
       "      <td>0.734265</td>\n",
       "      <td>523.300701</td>\n",
       "      <td>0.121297</td>\n",
       "      <td>0</td>\n",
       "      <td>dataset\\0\\fish_11.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.645835</td>\n",
       "      <td>0.895325</td>\n",
       "      <td>0.755612</td>\n",
       "      <td>431.792027</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.321500</td>\n",
       "      <td>0.830256</td>\n",
       "      <td>0.627472</td>\n",
       "      <td>697.592628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627253</td>\n",
       "      <td>695.672415</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.325453</td>\n",
       "      <td>0.848361</td>\n",
       "      <td>0.642111</td>\n",
       "      <td>623.203608</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0</td>\n",
       "      <td>dataset\\0\\fish_12.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Energy_0    Corr_0  Homogen_0  Contrast_0     ASM_0  Energy_45  \\\n",
       "0           0  0.360166  0.849100   0.715262  400.557698  0.129720   0.352685   \n",
       "1           0  0.400987  0.812333   0.749640  407.428869  0.160791   0.408181   \n",
       "2           0  0.376491  0.877119   0.798621  690.161206  0.141746   0.378780   \n",
       "3           0  0.348277  0.832274   0.694796  652.404336  0.121297   0.349204   \n",
       "4           0  0.645835  0.895325   0.755612  431.792027  0.131375   0.321500   \n",
       "\n",
       "    Corr_45  Homogen_45  Contrast_45  ...  Homogen_90  Contrast_90    ASM_90  \\\n",
       "0  0.830636    0.695192   449.911262  ...    0.697137   444.862077  0.129720   \n",
       "1  0.835459    0.768635   358.929444  ...    0.721557   478.110919  0.160791   \n",
       "2  0.881331    0.804157   665.580926  ...    0.821744   582.173172  0.141746   \n",
       "3  0.834127    0.699276   647.042470  ...    0.707651   618.055012  0.121297   \n",
       "4  0.830256    0.627472   697.592628  ...    0.627253   695.672415  0.131375   \n",
       "\n",
       "   Energy_135  Corr_135  Homogen_135  Contrast_135   ASM_135  output  \\\n",
       "0    0.371847  0.867505     0.744380    352.059009  0.129720       0   \n",
       "1    0.392616  0.782994     0.729269    473.488716  0.160791       0   \n",
       "2    0.374711  0.873295     0.793183    711.160952  0.141746       0   \n",
       "3    0.360706  0.865813     0.734265    523.300701  0.121297       0   \n",
       "4    0.325453  0.848361     0.642111    623.203608  0.131375       0   \n",
       "\n",
       "               filenames  \n",
       "0   dataset\\0\\fish_0.jpg  \n",
       "1   dataset\\0\\fish_1.jpg  \n",
       "2  dataset\\0\\fish_10.jpg  \n",
       "3  dataset\\0\\fish_11.jpg  \n",
       "4  dataset\\0\\fish_12.jpg  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"features.csv\")\n",
    "dt = pd.read_csv(\"Data_test.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af682c24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "af682c24",
    "outputId": "7b550838-f69d-4aa8-a81d-31d005ac9d90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy_0</th>\n",
       "      <th>Corr_0</th>\n",
       "      <th>Homogen_0</th>\n",
       "      <th>Contrast_0</th>\n",
       "      <th>ASM_0</th>\n",
       "      <th>Energy_45</th>\n",
       "      <th>Corr_45</th>\n",
       "      <th>Homogen_45</th>\n",
       "      <th>Contrast_45</th>\n",
       "      <th>ASM_45</th>\n",
       "      <th>...</th>\n",
       "      <th>Corr_90</th>\n",
       "      <th>Homogen_90</th>\n",
       "      <th>Contrast_90</th>\n",
       "      <th>ASM_90</th>\n",
       "      <th>Energy_135</th>\n",
       "      <th>Corr_135</th>\n",
       "      <th>Homogen_135</th>\n",
       "      <th>Contrast_135</th>\n",
       "      <th>ASM_135</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.360166</td>\n",
       "      <td>0.849100</td>\n",
       "      <td>0.715262</td>\n",
       "      <td>400.557698</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>0.352685</td>\n",
       "      <td>0.830636</td>\n",
       "      <td>0.695192</td>\n",
       "      <td>449.911262</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832495</td>\n",
       "      <td>0.697137</td>\n",
       "      <td>444.862077</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>0.371847</td>\n",
       "      <td>0.867505</td>\n",
       "      <td>0.744380</td>\n",
       "      <td>352.059009</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.400987</td>\n",
       "      <td>0.812333</td>\n",
       "      <td>0.749640</td>\n",
       "      <td>407.428869</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>0.408181</td>\n",
       "      <td>0.835459</td>\n",
       "      <td>0.768635</td>\n",
       "      <td>358.929444</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781798</td>\n",
       "      <td>0.721557</td>\n",
       "      <td>478.110919</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>0.392616</td>\n",
       "      <td>0.782994</td>\n",
       "      <td>0.729269</td>\n",
       "      <td>473.488716</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.376491</td>\n",
       "      <td>0.877119</td>\n",
       "      <td>0.798621</td>\n",
       "      <td>690.161206</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0.378780</td>\n",
       "      <td>0.881331</td>\n",
       "      <td>0.804157</td>\n",
       "      <td>665.580926</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896054</td>\n",
       "      <td>0.821744</td>\n",
       "      <td>582.173172</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0.374711</td>\n",
       "      <td>0.873295</td>\n",
       "      <td>0.793183</td>\n",
       "      <td>711.160952</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348277</td>\n",
       "      <td>0.832274</td>\n",
       "      <td>0.694796</td>\n",
       "      <td>652.404336</td>\n",
       "      <td>0.121297</td>\n",
       "      <td>0.349204</td>\n",
       "      <td>0.834127</td>\n",
       "      <td>0.699276</td>\n",
       "      <td>647.042470</td>\n",
       "      <td>0.121297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842687</td>\n",
       "      <td>0.707651</td>\n",
       "      <td>618.055012</td>\n",
       "      <td>0.121297</td>\n",
       "      <td>0.360706</td>\n",
       "      <td>0.865813</td>\n",
       "      <td>0.734265</td>\n",
       "      <td>523.300701</td>\n",
       "      <td>0.121297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.645835</td>\n",
       "      <td>0.895325</td>\n",
       "      <td>0.755612</td>\n",
       "      <td>431.792027</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.321500</td>\n",
       "      <td>0.830256</td>\n",
       "      <td>0.627472</td>\n",
       "      <td>697.592628</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830514</td>\n",
       "      <td>0.627253</td>\n",
       "      <td>695.672415</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.325453</td>\n",
       "      <td>0.848361</td>\n",
       "      <td>0.642111</td>\n",
       "      <td>623.203608</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Energy_0    Corr_0  Homogen_0  Contrast_0     ASM_0  Energy_45   Corr_45  \\\n",
       "0  0.360166  0.849100   0.715262  400.557698  0.129720   0.352685  0.830636   \n",
       "1  0.400987  0.812333   0.749640  407.428869  0.160791   0.408181  0.835459   \n",
       "2  0.376491  0.877119   0.798621  690.161206  0.141746   0.378780  0.881331   \n",
       "3  0.348277  0.832274   0.694796  652.404336  0.121297   0.349204  0.834127   \n",
       "4  0.645835  0.895325   0.755612  431.792027  0.131375   0.321500  0.830256   \n",
       "\n",
       "   Homogen_45  Contrast_45    ASM_45  ...   Corr_90  Homogen_90  Contrast_90  \\\n",
       "0    0.695192   449.911262  0.129720  ...  0.832495    0.697137   444.862077   \n",
       "1    0.768635   358.929444  0.160791  ...  0.781798    0.721557   478.110919   \n",
       "2    0.804157   665.580926  0.141746  ...  0.896054    0.821744   582.173172   \n",
       "3    0.699276   647.042470  0.121297  ...  0.842687    0.707651   618.055012   \n",
       "4    0.627472   697.592628  0.131375  ...  0.830514    0.627253   695.672415   \n",
       "\n",
       "     ASM_90  Energy_135  Corr_135  Homogen_135  Contrast_135   ASM_135  output  \n",
       "0  0.129720    0.371847  0.867505     0.744380    352.059009  0.129720       0  \n",
       "1  0.160791    0.392616  0.782994     0.729269    473.488716  0.160791       0  \n",
       "2  0.141746    0.374711  0.873295     0.793183    711.160952  0.141746       0  \n",
       "3  0.121297    0.360706  0.865813     0.734265    523.300701  0.121297       0  \n",
       "4  0.131375    0.325453  0.848361     0.642111    623.203608  0.131375       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['filenames'], axis=1, inplace=True)\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "037c422e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "037c422e",
    "outputId": "cb10143c-2bc0-4aef-c031-cc9471b79d26",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    62\n",
      "1    47\n",
      "2    16\n",
      "3    16\n",
      "Name: output, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_distr = df['output'].value_counts()\n",
    "\n",
    "label_name = ['Normal', 'RS', 'MAS', 'WS']\n",
    "\n",
    "print(label_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee848072",
   "metadata": {
    "id": "ee848072",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ee0a682",
   "metadata": {
    "id": "2ee0a682",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decimal_scaling(data):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    max_row = data.max(axis=0)\n",
    "    c = np.array([len(str(int(number))) for number in np.abs(max_row)])\n",
    "    return data / (10 ** c)\n",
    "\n",
    "\n",
    "X = decimal_scaling(df[['Energy_0', 'Corr_0', 'Homogen_0', 'Contrast_0', 'ASM_0',\n",
    "                        'Energy_45', 'Corr_45', 'Homogen_45', 'Contrast_45', 'ASM_45',\n",
    "                        'Energy_90', 'Corr_90', 'Homogen_90', 'Contrast_90', 'ASM_90',\n",
    "                        'Energy_135', 'Corr_135', 'Homogen_135', 'Contrast_135', 'ASM_135']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd8d281f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd8d281f",
    "outputId": "cd787bf6-27d5-4570-d11b-3638b05e69ba",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " categorical label : \n",
      " [0 1 2 3]\n",
      "\n",
      "\n",
      " one hot encoding for sample 0 : \n",
      " [1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df[\"output\"].values)\n",
    "\n",
    "print(\" categorical label : \\n\", le.classes_)\n",
    "\n",
    "Y = le.transform(df['output'].values)\n",
    "Y = to_categorical(Y)\n",
    "\n",
    "print(\"\\n\\n one hot encoding for sample 0 : \\n\", Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7b35b84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7b35b84",
    "outputId": "b478c4c9-de67-4300-ebfe-ac95a35b75f2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi data :\n",
      "\n",
      "X train \t X test \t Y train \t Y test\n",
      "(112, 20) \t (29, 20) \t (112, 4) \t (29, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2,random_state=42)\n",
    "\n",
    "print(\"Dimensi data :\\n\")\n",
    "print(\"X train \\t X test \\t Y train \\t Y test\")\n",
    "print(\"%s \\t %s \\t %s \\t %s\" % (X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b69e2e6b",
   "metadata": {
    "id": "b69e2e6b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14424bb3",
   "metadata": {
    "id": "14424bb3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def nn_model(max_len):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,\n",
    "                    activation=\"elu\",\n",
    "                    input_shape=(max_len,)))\n",
    "    model.add(Dense(128, activation=\"elu\"))\n",
    "    model.add(Dense(64, activation=\"elu\"))\n",
    "    model.add(Dense(32, activation=\"elu\"))\n",
    "    model.add(Dense(16, activation=\"elu\"))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', precision, recall])\n",
    "    return model\n",
    "\n",
    "\n",
    "def check_model(model_, x, y, x_val, y_val, epochs_, batch_size_):\n",
    "    hist = model_.fit(x,\n",
    "                      y,\n",
    "                      epochs=epochs_,\n",
    "                      batch_size=batch_size_,\n",
    "                      validation_data=(x_val, y_val))\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "802b6f8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "802b6f8b",
    "outputId": "d3b45ed7-79d8-4512-91d6-dd0b0b6984ae",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 32)                672       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,828\n",
      "Trainable params: 15,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "4/4 [==============================] - 1s 71ms/step - loss: 1.3194 - accuracy: 0.3214 - precision: 0.7031 - recall: 0.3707 - val_loss: 1.2272 - val_accuracy: 0.4828 - val_precision: 0.7931 - val_recall: 0.3966\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2188 - accuracy: 0.5089 - precision: 0.7812 - recall: 0.3906 - val_loss: 1.1575 - val_accuracy: 0.5862 - val_precision: 0.7931 - val_recall: 0.3966\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1858 - accuracy: 0.5714 - precision: 0.7734 - recall: 0.3867 - val_loss: 1.1279 - val_accuracy: 0.6207 - val_precision: 0.7931 - val_recall: 0.3966\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1671 - accuracy: 0.5804 - precision: 0.7734 - recall: 0.3867 - val_loss: 1.0966 - val_accuracy: 0.6207 - val_precision: 0.7931 - val_recall: 0.3966\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1297 - accuracy: 0.5893 - precision: 0.7812 - recall: 0.3906 - val_loss: 1.0597 - val_accuracy: 0.6207 - val_precision: 0.7931 - val_recall: 0.4035\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0911 - accuracy: 0.5893 - precision: 0.7500 - recall: 0.3820 - val_loss: 1.0275 - val_accuracy: 0.6207 - val_precision: 0.7931 - val_recall: 0.4259\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0645 - accuracy: 0.5893 - precision: 0.7734 - recall: 0.4239 - val_loss: 1.0041 - val_accuracy: 0.6207 - val_precision: 0.7931 - val_recall: 0.4792\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0378 - accuracy: 0.5893 - precision: 0.6953 - recall: 0.5217 - val_loss: 0.9861 - val_accuracy: 0.6207 - val_precision: 0.6552 - val_recall: 0.6333\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0229 - accuracy: 0.5893 - precision: 0.6406 - recall: 0.6126 - val_loss: 0.9698 - val_accuracy: 0.6207 - val_precision: 0.7241 - val_recall: 0.5833\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0067 - accuracy: 0.5982 - precision: 0.7188 - recall: 0.5708 - val_loss: 0.9583 - val_accuracy: 0.6207 - val_precision: 0.7931 - val_recall: 0.4792\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0030 - accuracy: 0.5982 - precision: 0.7656 - recall: 0.4453 - val_loss: 0.9531 - val_accuracy: 0.6207 - val_precision: 0.7931 - val_recall: 0.4340\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9920 - accuracy: 0.5982 - precision: 0.7812 - recall: 0.4703 - val_loss: 0.9389 - val_accuracy: 0.6207 - val_precision: 0.7241 - val_recall: 0.5526\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9827 - accuracy: 0.5982 - precision: 0.7188 - recall: 0.5451 - val_loss: 0.9341 - val_accuracy: 0.6207 - val_precision: 0.7241 - val_recall: 0.5833\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9776 - accuracy: 0.5982 - precision: 0.7266 - recall: 0.5556 - val_loss: 0.9280 - val_accuracy: 0.6207 - val_precision: 0.7241 - val_recall: 0.5385\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9710 - accuracy: 0.5982 - precision: 0.7422 - recall: 0.5104 - val_loss: 0.9227 - val_accuracy: 0.6207 - val_precision: 0.7241 - val_recall: 0.5250\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9660 - accuracy: 0.5982 - precision: 0.7266 - recall: 0.5534 - val_loss: 0.9171 - val_accuracy: 0.6207 - val_precision: 0.7241 - val_recall: 0.5833\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9562 - accuracy: 0.5982 - precision: 0.7344 - recall: 0.5796 - val_loss: 0.9117 - val_accuracy: 0.6207 - val_precision: 0.7241 - val_recall: 0.5833\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9491 - accuracy: 0.5982 - precision: 0.7188 - recall: 0.5682 - val_loss: 0.9025 - val_accuracy: 0.6207 - val_precision: 0.7241 - val_recall: 0.5833\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9541 - accuracy: 0.6071 - precision: 0.7422 - recall: 0.4957 - val_loss: 0.8947 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.5526\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9390 - accuracy: 0.6161 - precision: 0.6719 - recall: 0.5338 - val_loss: 0.8907 - val_accuracy: 0.6207 - val_precision: 0.7241 - val_recall: 0.6000\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9319 - accuracy: 0.6250 - precision: 0.7188 - recall: 0.5441 - val_loss: 0.8906 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.5000\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9218 - accuracy: 0.6161 - precision: 0.7422 - recall: 0.5131 - val_loss: 0.8723 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.5250\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9141 - accuracy: 0.6161 - precision: 0.7344 - recall: 0.5227 - val_loss: 0.8652 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.5250\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9003 - accuracy: 0.6339 - precision: 0.7188 - recall: 0.4601 - val_loss: 0.8682 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.4884\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8911 - accuracy: 0.6429 - precision: 0.7344 - recall: 0.4735 - val_loss: 0.8466 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.5122\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8867 - accuracy: 0.6250 - precision: 0.7188 - recall: 0.5005 - val_loss: 0.8371 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.5000\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8728 - accuracy: 0.6429 - precision: 0.7266 - recall: 0.4873 - val_loss: 0.8348 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.4773\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8650 - accuracy: 0.6518 - precision: 0.7422 - recall: 0.5192 - val_loss: 0.8284 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.4667\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8837 - accuracy: 0.6429 - precision: 0.7344 - recall: 0.4635 - val_loss: 0.8257 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.4667\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8459 - accuracy: 0.6696 - precision: 0.7422 - recall: 0.5017 - val_loss: 0.8389 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.4667\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8497 - accuracy: 0.6786 - precision: 0.7500 - recall: 0.4975 - val_loss: 0.8195 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.4773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8433 - accuracy: 0.6607 - precision: 0.7500 - recall: 0.5078 - val_loss: 0.8196 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.4884\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8372 - accuracy: 0.6696 - precision: 0.7500 - recall: 0.5041 - val_loss: 0.8111 - val_accuracy: 0.6552 - val_precision: 0.7241 - val_recall: 0.4667\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8333 - accuracy: 0.6607 - precision: 0.7656 - recall: 0.4823 - val_loss: 0.8083 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4889\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8347 - accuracy: 0.6429 - precision: 0.7656 - recall: 0.4737 - val_loss: 0.8102 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4783\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8222 - accuracy: 0.6607 - precision: 0.7734 - recall: 0.4704 - val_loss: 0.8090 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4889\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8226 - accuracy: 0.6607 - precision: 0.7812 - recall: 0.4821 - val_loss: 0.8121 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4889\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8129 - accuracy: 0.6607 - precision: 0.7734 - recall: 0.4900 - val_loss: 0.8133 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4889\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8090 - accuracy: 0.6696 - precision: 0.7578 - recall: 0.4821 - val_loss: 0.8131 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4783\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8100 - accuracy: 0.6607 - precision: 0.7656 - recall: 0.4813 - val_loss: 0.8120 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4783\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8025 - accuracy: 0.6607 - precision: 0.7812 - recall: 0.4984 - val_loss: 0.7936 - val_accuracy: 0.6897 - val_precision: 0.7586 - val_recall: 0.4889\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8424 - accuracy: 0.6607 - precision: 0.7891 - recall: 0.4668 - val_loss: 0.7973 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4889\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9243 - accuracy: 0.6250 - precision: 0.8125 - recall: 0.4822 - val_loss: 0.7864 - val_accuracy: 0.6897 - val_precision: 0.8621 - val_recall: 0.5102\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8427 - accuracy: 0.6518 - precision: 0.7891 - recall: 0.4592 - val_loss: 0.8162 - val_accuracy: 0.6552 - val_precision: 0.8276 - val_recall: 0.4444\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8121 - accuracy: 0.6339 - precision: 0.7656 - recall: 0.4493 - val_loss: 0.8684 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4681\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8311 - accuracy: 0.6607 - precision: 0.8203 - recall: 0.5090 - val_loss: 0.7841 - val_accuracy: 0.6897 - val_precision: 0.8276 - val_recall: 0.5106\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8034 - accuracy: 0.6518 - precision: 0.8203 - recall: 0.5000 - val_loss: 0.7847 - val_accuracy: 0.6552 - val_precision: 0.8276 - val_recall: 0.5000\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8009 - accuracy: 0.6607 - precision: 0.8359 - recall: 0.5184 - val_loss: 0.7908 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4783\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7982 - accuracy: 0.6607 - precision: 0.7656 - recall: 0.4796 - val_loss: 0.7858 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4783\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8024 - accuracy: 0.6607 - precision: 0.7734 - recall: 0.4968 - val_loss: 0.7751 - val_accuracy: 0.6897 - val_precision: 0.7586 - val_recall: 0.5000\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7994 - accuracy: 0.6875 - precision: 0.7812 - recall: 0.4971 - val_loss: 0.7883 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4783\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7956 - accuracy: 0.6429 - precision: 0.8281 - recall: 0.4918 - val_loss: 0.7776 - val_accuracy: 0.6897 - val_precision: 0.8621 - val_recall: 0.5102\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7905 - accuracy: 0.6786 - precision: 0.8828 - recall: 0.5251 - val_loss: 0.7905 - val_accuracy: 0.6552 - val_precision: 0.7931 - val_recall: 0.4894\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7823 - accuracy: 0.7054 - precision: 0.8516 - recall: 0.5062 - val_loss: 0.7691 - val_accuracy: 0.6552 - val_precision: 0.8621 - val_recall: 0.5102\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7687 - accuracy: 0.6964 - precision: 0.8672 - recall: 0.5334 - val_loss: 0.7801 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4783\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7926 - accuracy: 0.6696 - precision: 0.8125 - recall: 0.5047 - val_loss: 0.7688 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.4889\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8096 - accuracy: 0.6607 - precision: 0.7422 - recall: 0.4901 - val_loss: 0.7692 - val_accuracy: 0.6897 - val_precision: 0.7586 - val_recall: 0.5000\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7632 - accuracy: 0.6696 - precision: 0.7812 - recall: 0.5059 - val_loss: 0.8365 - val_accuracy: 0.6552 - val_precision: 0.7586 - val_recall: 0.5000\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7888 - accuracy: 0.7054 - precision: 0.7969 - recall: 0.5017 - val_loss: 0.7614 - val_accuracy: 0.6897 - val_precision: 0.8276 - val_recall: 0.5217\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7741 - accuracy: 0.6875 - precision: 0.8125 - recall: 0.5178 - val_loss: 0.7547 - val_accuracy: 0.6897 - val_precision: 0.8276 - val_recall: 0.5217\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7550 - accuracy: 0.7054 - precision: 0.8516 - recall: 0.5324 - val_loss: 0.7569 - val_accuracy: 0.6207 - val_precision: 0.8276 - val_recall: 0.5106\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7510 - accuracy: 0.6875 - precision: 0.8672 - recall: 0.5314 - val_loss: 0.7530 - val_accuracy: 0.6552 - val_precision: 0.8276 - val_recall: 0.5000\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7452 - accuracy: 0.6964 - precision: 0.8438 - recall: 0.5276 - val_loss: 0.7463 - val_accuracy: 0.6552 - val_precision: 0.8276 - val_recall: 0.5000\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7405 - accuracy: 0.6875 - precision: 0.8359 - recall: 0.5262 - val_loss: 0.7481 - val_accuracy: 0.6552 - val_precision: 0.8276 - val_recall: 0.5455\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7407 - accuracy: 0.6607 - precision: 0.8750 - recall: 0.5386 - val_loss: 0.7409 - val_accuracy: 0.6207 - val_precision: 0.8276 - val_recall: 0.5455\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7359 - accuracy: 0.6696 - precision: 0.8516 - recall: 0.5350 - val_loss: 0.7354 - val_accuracy: 0.6552 - val_precision: 0.8276 - val_recall: 0.5333\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7350 - accuracy: 0.6875 - precision: 0.8516 - recall: 0.5251 - val_loss: 0.7371 - val_accuracy: 0.6207 - val_precision: 0.8276 - val_recall: 0.5333\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7364 - accuracy: 0.6964 - precision: 0.8672 - recall: 0.5300 - val_loss: 0.7314 - val_accuracy: 0.6207 - val_precision: 0.8276 - val_recall: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7251 - accuracy: 0.6786 - precision: 0.8828 - recall: 0.5468 - val_loss: 0.7260 - val_accuracy: 0.6207 - val_precision: 0.8621 - val_recall: 0.5435\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7253 - accuracy: 0.7143 - precision: 0.8750 - recall: 0.5459 - val_loss: 0.7254 - val_accuracy: 0.7241 - val_precision: 0.8621 - val_recall: 0.5102\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7166 - accuracy: 0.7500 - precision: 0.8750 - recall: 0.5302 - val_loss: 0.7194 - val_accuracy: 0.6552 - val_precision: 0.8621 - val_recall: 0.5102\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7220 - accuracy: 0.7232 - precision: 0.8516 - recall: 0.5413 - val_loss: 0.7187 - val_accuracy: 0.7241 - val_precision: 0.8621 - val_recall: 0.5208\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7230 - accuracy: 0.7500 - precision: 0.8828 - recall: 0.5356 - val_loss: 0.7094 - val_accuracy: 0.6897 - val_precision: 0.8621 - val_recall: 0.5435\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7016 - accuracy: 0.7321 - precision: 0.8906 - recall: 0.5650 - val_loss: 0.7106 - val_accuracy: 0.6552 - val_precision: 0.8276 - val_recall: 0.5106\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7383 - accuracy: 0.7143 - precision: 0.8125 - recall: 0.5158 - val_loss: 0.6933 - val_accuracy: 0.6897 - val_precision: 0.8621 - val_recall: 0.5435\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6981 - accuracy: 0.7679 - precision: 0.9141 - recall: 0.5441 - val_loss: 0.6994 - val_accuracy: 0.7241 - val_precision: 0.8621 - val_recall: 0.5319\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6883 - accuracy: 0.7500 - precision: 0.9062 - recall: 0.5485 - val_loss: 0.6886 - val_accuracy: 0.6552 - val_precision: 0.8276 - val_recall: 0.5217\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7100 - accuracy: 0.7054 - precision: 0.8594 - recall: 0.5407 - val_loss: 0.6842 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5532\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7132 - accuracy: 0.7589 - precision: 0.9062 - recall: 0.5369 - val_loss: 0.6735 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5200\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.7232 - precision: 0.8672 - recall: 0.5382 - val_loss: 0.7103 - val_accuracy: 0.6552 - val_precision: 0.8966 - val_recall: 0.5417\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7507 - accuracy: 0.7232 - precision: 0.8359 - recall: 0.5044 - val_loss: 0.7000 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5000\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6855 - accuracy: 0.7500 - precision: 0.8750 - recall: 0.5169 - val_loss: 0.6708 - val_accuracy: 0.6552 - val_precision: 0.8621 - val_recall: 0.5319\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7061 - accuracy: 0.7054 - precision: 0.8359 - recall: 0.5316 - val_loss: 0.6545 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5200\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7047 - accuracy: 0.7768 - precision: 0.8594 - recall: 0.4995 - val_loss: 0.6613 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5652\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6632 - accuracy: 0.7768 - precision: 0.8984 - recall: 0.5448 - val_loss: 0.6654 - val_accuracy: 0.6552 - val_precision: 0.8621 - val_recall: 0.5208\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6811 - accuracy: 0.6964 - precision: 0.8438 - recall: 0.5266 - val_loss: 0.6494 - val_accuracy: 0.6897 - val_precision: 0.8966 - val_recall: 0.5200\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6647 - accuracy: 0.7589 - precision: 0.8672 - recall: 0.5101 - val_loss: 0.6445 - val_accuracy: 0.6897 - val_precision: 0.8966 - val_recall: 0.5200\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6543 - accuracy: 0.7679 - precision: 0.9062 - recall: 0.5153 - val_loss: 0.6459 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5532\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6597 - accuracy: 0.7768 - precision: 0.9219 - recall: 0.5409 - val_loss: 0.6311 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5200\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6596 - accuracy: 0.7589 - precision: 0.8516 - recall: 0.5137 - val_loss: 0.6281 - val_accuracy: 0.7586 - val_precision: 0.8966 - val_recall: 0.5306\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6785 - accuracy: 0.7857 - precision: 0.8828 - recall: 0.5009 - val_loss: 0.6442 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5532\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6400 - accuracy: 0.8036 - precision: 0.9219 - recall: 0.5321 - val_loss: 0.6379 - val_accuracy: 0.6552 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6581 - accuracy: 0.7411 - precision: 0.8828 - recall: 0.5304 - val_loss: 0.6104 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5306\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6396 - accuracy: 0.7679 - precision: 0.9219 - recall: 0.5317 - val_loss: 0.6185 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5532\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6301 - accuracy: 0.7768 - precision: 0.9141 - recall: 0.5279 - val_loss: 0.6118 - val_accuracy: 0.7586 - val_precision: 0.8966 - val_recall: 0.5417\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6613 - accuracy: 0.7321 - precision: 0.8594 - recall: 0.5263 - val_loss: 0.6011 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5652\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6364 - accuracy: 0.7857 - precision: 0.9219 - recall: 0.5379 - val_loss: 0.5960 - val_accuracy: 0.6897 - val_precision: 0.8966 - val_recall: 0.5652\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6314 - accuracy: 0.7946 - precision: 0.8906 - recall: 0.5254 - val_loss: 0.5954 - val_accuracy: 0.7586 - val_precision: 0.8966 - val_recall: 0.5652\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6236 - accuracy: 0.7768 - precision: 0.9141 - recall: 0.5360 - val_loss: 0.6085 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5532\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6121 - accuracy: 0.7768 - precision: 0.9141 - recall: 0.5553 - val_loss: 0.6036 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6259 - accuracy: 0.8036 - precision: 0.8750 - recall: 0.5407 - val_loss: 0.5897 - val_accuracy: 0.7586 - val_precision: 0.8966 - val_recall: 0.5652\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6150 - accuracy: 0.7946 - precision: 0.8906 - recall: 0.5409 - val_loss: 0.5980 - val_accuracy: 0.6897 - val_precision: 0.8966 - val_recall: 0.5652\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6173 - accuracy: 0.7946 - precision: 0.8984 - recall: 0.5270 - val_loss: 0.5810 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5909\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6422 - accuracy: 0.7411 - precision: 0.8828 - recall: 0.5191 - val_loss: 0.5823 - val_accuracy: 0.7241 - val_precision: 0.9310 - val_recall: 0.5745\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6054 - accuracy: 0.7768 - precision: 0.9219 - recall: 0.5425 - val_loss: 0.5947 - val_accuracy: 0.6897 - val_precision: 0.8621 - val_recall: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6046 - accuracy: 0.7946 - precision: 0.8984 - recall: 0.5475 - val_loss: 0.5862 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5870\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6084 - accuracy: 0.8036 - precision: 0.9141 - recall: 0.5570 - val_loss: 0.5676 - val_accuracy: 0.6897 - val_precision: 0.8966 - val_recall: 0.5778\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5989 - accuracy: 0.8036 - precision: 0.8906 - recall: 0.5507 - val_loss: 0.5564 - val_accuracy: 0.7586 - val_precision: 0.8966 - val_recall: 0.5778\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6020 - accuracy: 0.7946 - precision: 0.9141 - recall: 0.5398 - val_loss: 0.5583 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.6047\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6137 - accuracy: 0.7679 - precision: 0.9062 - recall: 0.5460 - val_loss: 0.5550 - val_accuracy: 0.7586 - val_precision: 0.8966 - val_recall: 0.6047\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6050 - accuracy: 0.8036 - precision: 0.9062 - recall: 0.5303 - val_loss: 0.5554 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5745\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5808 - accuracy: 0.8036 - precision: 0.9297 - recall: 0.5723 - val_loss: 0.5787 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5652\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6275 - accuracy: 0.7500 - precision: 0.8750 - recall: 0.5314 - val_loss: 0.5443 - val_accuracy: 0.6897 - val_precision: 0.8966 - val_recall: 0.5909\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6327 - accuracy: 0.7589 - precision: 0.8828 - recall: 0.5393 - val_loss: 0.5459 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5778\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6256 - accuracy: 0.7768 - precision: 0.8750 - recall: 0.4921 - val_loss: 0.6055 - val_accuracy: 0.6897 - val_precision: 0.8966 - val_recall: 0.5200\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6156 - accuracy: 0.7679 - precision: 0.9141 - recall: 0.5086 - val_loss: 0.5898 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5532\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5909 - accuracy: 0.7857 - precision: 0.9219 - recall: 0.5489 - val_loss: 0.5542 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5987 - accuracy: 0.8036 - precision: 0.8984 - recall: 0.5263 - val_loss: 0.5338 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5870\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5705 - accuracy: 0.7946 - precision: 0.8906 - recall: 0.5327 - val_loss: 0.5479 - val_accuracy: 0.7586 - val_precision: 0.8966 - val_recall: 0.5652\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5908 - accuracy: 0.7589 - precision: 0.9141 - recall: 0.5278 - val_loss: 0.5394 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5745\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5742 - accuracy: 0.7500 - precision: 0.9141 - recall: 0.5467 - val_loss: 0.5373 - val_accuracy: 0.7586 - val_precision: 0.8966 - val_recall: 0.5652\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5622 - accuracy: 0.7768 - precision: 0.9141 - recall: 0.5803 - val_loss: 0.5258 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5745\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5694 - accuracy: 0.8036 - precision: 0.8906 - recall: 0.5278 - val_loss: 0.5212 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5870\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5785 - accuracy: 0.7946 - precision: 0.9062 - recall: 0.5536 - val_loss: 0.5300 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5778\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5544 - accuracy: 0.7946 - precision: 0.9141 - recall: 0.5396 - val_loss: 0.5495 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5607 - accuracy: 0.7946 - precision: 0.9219 - recall: 0.5615 - val_loss: 0.5342 - val_accuracy: 0.7586 - val_precision: 0.8966 - val_recall: 0.5652\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5851 - accuracy: 0.7679 - precision: 0.8984 - recall: 0.5449 - val_loss: 0.5090 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5745\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5474 - accuracy: 0.7946 - precision: 0.8984 - recall: 0.5408 - val_loss: 0.5054 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5532\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5456 - accuracy: 0.7768 - precision: 0.8906 - recall: 0.5236 - val_loss: 0.4968 - val_accuracy: 0.7241 - val_precision: 0.9310 - val_recall: 0.5745\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5453 - accuracy: 0.8125 - precision: 0.9141 - recall: 0.5229 - val_loss: 0.5014 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5532\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5360 - accuracy: 0.7768 - precision: 0.9062 - recall: 0.5353 - val_loss: 0.5042 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5745\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5407 - accuracy: 0.8036 - precision: 0.9219 - recall: 0.5146 - val_loss: 0.5097 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.5417\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5428 - accuracy: 0.7857 - precision: 0.9219 - recall: 0.5253 - val_loss: 0.5007 - val_accuracy: 0.6897 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5282 - accuracy: 0.8125 - precision: 0.9297 - recall: 0.5258 - val_loss: 0.4925 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5279 - accuracy: 0.8393 - precision: 0.9141 - recall: 0.5097 - val_loss: 0.5002 - val_accuracy: 0.7931 - val_precision: 0.8966 - val_recall: 0.5306\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.8125 - precision: 0.9062 - recall: 0.5090 - val_loss: 0.4864 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5209 - accuracy: 0.7679 - precision: 0.9141 - recall: 0.4922 - val_loss: 0.4817 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5329 - accuracy: 0.7768 - precision: 0.9141 - recall: 0.5029 - val_loss: 0.4925 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5192\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5696 - accuracy: 0.8036 - precision: 0.9219 - recall: 0.4974 - val_loss: 0.4712 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5226 - accuracy: 0.8214 - precision: 0.8984 - recall: 0.5039 - val_loss: 0.4744 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5168 - accuracy: 0.8125 - precision: 0.9141 - recall: 0.4996 - val_loss: 0.4787 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5151 - accuracy: 0.7679 - precision: 0.9531 - recall: 0.5088 - val_loss: 0.4835 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5069 - accuracy: 0.7946 - precision: 0.9297 - recall: 0.5097 - val_loss: 0.4760 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5140 - accuracy: 0.8036 - precision: 0.9297 - recall: 0.5066 - val_loss: 0.4695 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5202 - accuracy: 0.8125 - precision: 0.9453 - recall: 0.5156 - val_loss: 0.4620 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5030 - accuracy: 0.8036 - precision: 0.9219 - recall: 0.5043 - val_loss: 0.4669 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5060 - accuracy: 0.7946 - precision: 0.9531 - recall: 0.5247 - val_loss: 0.4581 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5263 - accuracy: 0.7857 - precision: 0.9375 - recall: 0.5247 - val_loss: 0.4718 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5580 - accuracy: 0.8036 - precision: 0.9141 - recall: 0.4837 - val_loss: 0.4542 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5192\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5134 - accuracy: 0.7946 - precision: 0.9219 - recall: 0.4872 - val_loss: 0.4670 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5192\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5121 - accuracy: 0.7857 - precision: 0.9375 - recall: 0.5046 - val_loss: 0.4551 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5844 - accuracy: 0.8125 - precision: 0.9219 - recall: 0.4858 - val_loss: 0.4765 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6842 - accuracy: 0.7500 - precision: 0.8594 - recall: 0.4650 - val_loss: 0.4550 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5192\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7127 - accuracy: 0.6875 - precision: 0.9141 - recall: 0.4774 - val_loss: 0.5488 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5829 - accuracy: 0.7768 - precision: 0.9297 - recall: 0.4903 - val_loss: 0.6982 - val_accuracy: 0.7241 - val_precision: 0.8966 - val_recall: 0.4727\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6702 - accuracy: 0.7679 - precision: 0.8906 - recall: 0.4758 - val_loss: 0.5271 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5094\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5681 - accuracy: 0.7589 - precision: 0.9297 - recall: 0.5067 - val_loss: 0.4951 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5271 - accuracy: 0.7857 - precision: 0.9453 - recall: 0.5005 - val_loss: 0.5376 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5000\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5381 - accuracy: 0.7857 - precision: 0.9453 - recall: 0.5054 - val_loss: 0.4956 - val_accuracy: 0.7931 - val_precision: 0.8966 - val_recall: 0.5200\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5387 - accuracy: 0.7768 - precision: 0.9141 - recall: 0.5317 - val_loss: 0.4771 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5077 - accuracy: 0.7857 - precision: 0.9297 - recall: 0.5131 - val_loss: 0.5061 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5041 - accuracy: 0.8036 - precision: 0.9219 - recall: 0.5246 - val_loss: 0.5117 - val_accuracy: 0.7586 - val_precision: 0.8966 - val_recall: 0.5417\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5304 - accuracy: 0.7857 - precision: 0.9297 - recall: 0.5200 - val_loss: 0.4576 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.8214 - precision: 0.9219 - recall: 0.5111 - val_loss: 0.4806 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5059 - accuracy: 0.8393 - precision: 0.9141 - recall: 0.5202 - val_loss: 0.4615 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5147 - accuracy: 0.7768 - precision: 0.8984 - recall: 0.5115 - val_loss: 0.4654 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4989 - accuracy: 0.8036 - precision: 0.9297 - recall: 0.5089 - val_loss: 0.4663 - val_accuracy: 0.7586 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.7946 - precision: 0.9219 - recall: 0.4959 - val_loss: 0.4405 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5015 - accuracy: 0.8125 - precision: 0.9219 - recall: 0.5190 - val_loss: 0.4521 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.8393 - precision: 0.9375 - recall: 0.5107 - val_loss: 0.4491 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4866 - accuracy: 0.8125 - precision: 0.9453 - recall: 0.5280 - val_loss: 0.4441 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4837 - accuracy: 0.8214 - precision: 0.9219 - recall: 0.5003 - val_loss: 0.4344 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4796 - accuracy: 0.7946 - precision: 0.9531 - recall: 0.5110 - val_loss: 0.4317 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4789 - accuracy: 0.8214 - precision: 0.9297 - recall: 0.5021 - val_loss: 0.4272 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.8125 - precision: 0.9375 - recall: 0.5084 - val_loss: 0.4246 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4875 - accuracy: 0.8304 - precision: 0.9297 - recall: 0.4958 - val_loss: 0.4284 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4739 - accuracy: 0.8125 - precision: 0.9297 - recall: 0.5027 - val_loss: 0.4366 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.7768 - precision: 0.9453 - recall: 0.5038 - val_loss: 0.4413 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5336 - accuracy: 0.8125 - precision: 0.9297 - recall: 0.4917 - val_loss: 0.4216 - val_accuracy: 0.8621 - val_precision: 0.9310 - val_recall: 0.5192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5223 - accuracy: 0.7946 - precision: 0.9297 - recall: 0.5088 - val_loss: 0.4240 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5011 - accuracy: 0.8125 - precision: 0.9219 - recall: 0.4944 - val_loss: 0.4742 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5000\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4947 - accuracy: 0.8214 - precision: 0.9297 - recall: 0.4861 - val_loss: 0.4485 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5192\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5270 - accuracy: 0.7857 - precision: 0.9297 - recall: 0.4936 - val_loss: 0.4508 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5237 - accuracy: 0.7946 - precision: 0.9062 - recall: 0.4825 - val_loss: 0.4207 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5422 - accuracy: 0.7857 - precision: 0.9453 - recall: 0.4972 - val_loss: 0.4997 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5000\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5240 - accuracy: 0.8125 - precision: 0.9141 - recall: 0.4863 - val_loss: 0.5489 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.4909\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5304 - accuracy: 0.7946 - precision: 0.9141 - recall: 0.5015 - val_loss: 0.4587 - val_accuracy: 0.7931 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5104 - accuracy: 0.7589 - precision: 0.9297 - recall: 0.4962 - val_loss: 0.4318 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4855 - accuracy: 0.8304 - precision: 0.8906 - recall: 0.4939 - val_loss: 0.4335 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5456 - accuracy: 0.7946 - precision: 0.8984 - recall: 0.4955 - val_loss: 0.4425 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5283\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4824 - accuracy: 0.7946 - precision: 0.9453 - recall: 0.5171 - val_loss: 0.5304 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5094\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4874 - accuracy: 0.8304 - precision: 0.9297 - recall: 0.5065 - val_loss: 0.4653 - val_accuracy: 0.7931 - val_precision: 0.9310 - val_recall: 0.5094\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5060 - accuracy: 0.7589 - precision: 0.9062 - recall: 0.4878 - val_loss: 0.4302 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5241 - accuracy: 0.7946 - precision: 0.9062 - recall: 0.4800 - val_loss: 0.5143 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5000\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4640 - accuracy: 0.7946 - precision: 0.9375 - recall: 0.5066 - val_loss: 0.5764 - val_accuracy: 0.7931 - val_precision: 0.8966 - val_recall: 0.4906\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5807 - accuracy: 0.7679 - precision: 0.9141 - recall: 0.4965 - val_loss: 0.4665 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4674 - accuracy: 0.8036 - precision: 0.9297 - recall: 0.4996 - val_loss: 0.4294 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4603 - accuracy: 0.8482 - precision: 0.9375 - recall: 0.5151 - val_loss: 0.4209 - val_accuracy: 0.8621 - val_precision: 0.9310 - val_recall: 0.5094\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4610 - accuracy: 0.8304 - precision: 0.9453 - recall: 0.5228 - val_loss: 0.4190 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4519 - accuracy: 0.8214 - precision: 0.9531 - recall: 0.5113 - val_loss: 0.4390 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5745\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.8125 - precision: 0.9453 - recall: 0.5332 - val_loss: 0.4113 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4531 - accuracy: 0.8304 - precision: 0.9453 - recall: 0.5063 - val_loss: 0.4147 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4504 - accuracy: 0.8214 - precision: 0.9453 - recall: 0.5084 - val_loss: 0.4224 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4724 - accuracy: 0.8214 - precision: 0.9297 - recall: 0.5006 - val_loss: 0.4098 - val_accuracy: 0.7931 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4766 - accuracy: 0.8125 - precision: 0.9531 - recall: 0.5083 - val_loss: 0.4038 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4532 - accuracy: 0.8304 - precision: 0.9453 - recall: 0.5000 - val_loss: 0.4271 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4464 - accuracy: 0.8304 - precision: 0.9297 - recall: 0.4979 - val_loss: 0.4148 - val_accuracy: 0.7931 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4493 - accuracy: 0.8304 - precision: 0.9688 - recall: 0.5086 - val_loss: 0.4085 - val_accuracy: 0.7931 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4447 - accuracy: 0.8304 - precision: 0.9375 - recall: 0.4929 - val_loss: 0.4204 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4551 - accuracy: 0.8393 - precision: 0.9453 - recall: 0.4962 - val_loss: 0.4060 - val_accuracy: 0.8621 - val_precision: 0.9310 - val_recall: 0.5192\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4440 - accuracy: 0.8571 - precision: 0.9453 - recall: 0.5048 - val_loss: 0.4385 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4428 - accuracy: 0.8571 - precision: 0.9531 - recall: 0.5105 - val_loss: 0.4128 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4485 - accuracy: 0.8125 - precision: 0.9609 - recall: 0.5131 - val_loss: 0.4180 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4650 - accuracy: 0.8393 - precision: 0.9375 - recall: 0.4964 - val_loss: 0.4017 - val_accuracy: 0.8621 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.8393 - precision: 0.9375 - recall: 0.4903 - val_loss: 0.3936 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4395 - accuracy: 0.8214 - precision: 0.9531 - recall: 0.5099 - val_loss: 0.4289 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4395 - accuracy: 0.8214 - precision: 0.9688 - recall: 0.5065 - val_loss: 0.4035 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4320 - accuracy: 0.8304 - precision: 0.9688 - recall: 0.5061 - val_loss: 0.4232 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4603 - accuracy: 0.8304 - precision: 0.9531 - recall: 0.4921 - val_loss: 0.3936 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4297 - accuracy: 0.8482 - precision: 0.9688 - recall: 0.5001 - val_loss: 0.3977 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4278 - accuracy: 0.8393 - precision: 0.9609 - recall: 0.5020 - val_loss: 0.4258 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4288 - accuracy: 0.8571 - precision: 0.9453 - recall: 0.4888 - val_loss: 0.3946 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4526 - accuracy: 0.8214 - precision: 0.9609 - recall: 0.4906 - val_loss: 0.4069 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4276 - accuracy: 0.8393 - precision: 0.9609 - recall: 0.4964 - val_loss: 0.4310 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.8482 - precision: 0.9375 - recall: 0.4845 - val_loss: 0.3994 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4573 - accuracy: 0.8304 - precision: 0.9609 - recall: 0.5063 - val_loss: 0.4144 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4607 - accuracy: 0.8393 - precision: 0.9609 - recall: 0.4886 - val_loss: 0.3998 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4285 - accuracy: 0.8482 - precision: 0.9531 - recall: 0.5003 - val_loss: 0.3764 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4135 - accuracy: 0.8482 - precision: 0.9688 - recall: 0.5000 - val_loss: 0.4206 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4583 - accuracy: 0.8125 - precision: 0.9609 - recall: 0.4962 - val_loss: 0.3900 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4373 - accuracy: 0.8393 - precision: 0.9766 - recall: 0.4922 - val_loss: 0.4226 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5140 - accuracy: 0.8036 - precision: 0.9297 - recall: 0.4838 - val_loss: 0.4030 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5145 - accuracy: 0.7857 - precision: 0.9297 - recall: 0.4921 - val_loss: 0.4135 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5257 - accuracy: 0.7946 - precision: 0.9141 - recall: 0.4733 - val_loss: 0.4189 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4451 - accuracy: 0.8214 - precision: 0.9453 - recall: 0.4880 - val_loss: 0.4833 - val_accuracy: 0.7931 - val_precision: 0.8966 - val_recall: 0.4815\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4586 - accuracy: 0.7946 - precision: 0.9531 - recall: 0.4910 - val_loss: 0.5123 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5000\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4908 - accuracy: 0.8125 - precision: 0.9531 - recall: 0.4842 - val_loss: 0.4155 - val_accuracy: 0.7931 - val_precision: 0.9655 - val_recall: 0.5185\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4854 - accuracy: 0.7857 - precision: 0.9609 - recall: 0.4903 - val_loss: 0.4090 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4237 - accuracy: 0.8661 - precision: 0.9531 - recall: 0.4846 - val_loss: 0.4192 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.8393 - precision: 0.9609 - recall: 0.4922 - val_loss: 0.4102 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8214 - precision: 0.9688 - recall: 0.5014 - val_loss: 0.4227 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.8571 - precision: 0.9688 - recall: 0.5083 - val_loss: 0.4173 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4251 - accuracy: 0.8482 - precision: 0.9688 - recall: 0.5058 - val_loss: 0.3999 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5625\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.8482 - precision: 0.9375 - recall: 0.4967 - val_loss: 0.4054 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8393 - precision: 0.9688 - recall: 0.5024 - val_loss: 0.3941 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4195 - accuracy: 0.8304 - precision: 0.9531 - recall: 0.5055 - val_loss: 0.4060 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4107 - accuracy: 0.8482 - precision: 0.9609 - recall: 0.4921 - val_loss: 0.3933 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4075 - accuracy: 0.8304 - precision: 0.9766 - recall: 0.5027 - val_loss: 0.4106 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5400\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4265 - accuracy: 0.8125 - precision: 0.9688 - recall: 0.5025 - val_loss: 0.4224 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4420 - accuracy: 0.8482 - precision: 0.9609 - recall: 0.4890 - val_loss: 0.3927 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.8393 - precision: 0.9688 - recall: 0.4806 - val_loss: 0.3886 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8661 - precision: 0.9688 - recall: 0.4904 - val_loss: 0.4138 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3943 - accuracy: 0.8661 - precision: 0.9766 - recall: 0.4923 - val_loss: 0.3882 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4271 - accuracy: 0.8482 - precision: 0.9688 - recall: 0.4888 - val_loss: 0.3891 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5294\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4072 - accuracy: 0.8482 - precision: 0.9766 - recall: 0.4942 - val_loss: 0.3916 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4337 - accuracy: 0.8304 - precision: 0.9688 - recall: 0.4894 - val_loss: 0.4009 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4486 - accuracy: 0.8393 - precision: 0.9688 - recall: 0.4808 - val_loss: 0.3847 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3974 - accuracy: 0.8661 - precision: 0.9531 - recall: 0.4896 - val_loss: 0.4059 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3966 - accuracy: 0.8661 - precision: 0.9688 - recall: 0.4949 - val_loss: 0.3867 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3934 - accuracy: 0.8482 - precision: 0.9688 - recall: 0.4849 - val_loss: 0.3904 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5600\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3965 - accuracy: 0.8571 - precision: 0.9766 - recall: 0.4932 - val_loss: 0.4100 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4000 - accuracy: 0.8661 - precision: 0.9766 - recall: 0.4952 - val_loss: 0.4131 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5283\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.8482 - precision: 0.9609 - recall: 0.5022 - val_loss: 0.3742 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5091\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.8393 - precision: 0.9609 - recall: 0.4696 - val_loss: 0.3993 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5283\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4414 - accuracy: 0.8304 - precision: 0.9688 - recall: 0.4811 - val_loss: 0.4026 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4246 - accuracy: 0.7946 - precision: 0.9688 - recall: 0.4904 - val_loss: 0.3820 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5283\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4263 - accuracy: 0.8304 - precision: 0.9609 - recall: 0.4864 - val_loss: 0.4125 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5283\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4022 - accuracy: 0.8393 - precision: 0.9688 - recall: 0.4884 - val_loss: 0.3757 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5185\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4001 - accuracy: 0.8482 - precision: 0.9609 - recall: 0.4881 - val_loss: 0.4222 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5490\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8750 - precision: 0.9766 - recall: 0.4885 - val_loss: 0.3997 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5600\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4224 - accuracy: 0.8125 - precision: 0.9688 - recall: 0.4942 - val_loss: 0.3899 - val_accuracy: 0.8276 - val_precision: 0.9310 - val_recall: 0.5510\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3821 - accuracy: 0.8304 - precision: 0.9766 - recall: 0.4859 - val_loss: 0.3723 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5000\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4265 - accuracy: 0.8393 - precision: 0.9531 - recall: 0.4808 - val_loss: 0.3979 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3957 - accuracy: 0.8214 - precision: 0.9688 - recall: 0.4830 - val_loss: 0.3724 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5185\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4041 - accuracy: 0.8304 - precision: 0.9688 - recall: 0.4861 - val_loss: 0.4088 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3999 - accuracy: 0.8661 - precision: 0.9766 - recall: 0.4859 - val_loss: 0.3861 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3971 - accuracy: 0.8571 - precision: 0.9609 - recall: 0.4925 - val_loss: 0.4182 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3779 - accuracy: 0.8750 - precision: 0.9766 - recall: 0.4942 - val_loss: 0.3847 - val_accuracy: 0.8966 - val_precision: 0.9655 - val_recall: 0.4912\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4386 - accuracy: 0.8571 - precision: 0.9688 - recall: 0.4754 - val_loss: 0.4661 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5185\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4209 - accuracy: 0.8571 - precision: 0.9688 - recall: 0.4883 - val_loss: 0.3805 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5283\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4022 - accuracy: 0.8839 - precision: 0.9688 - recall: 0.4977 - val_loss: 0.4383 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5185\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3960 - accuracy: 0.8750 - precision: 0.9609 - recall: 0.4751 - val_loss: 0.3755 - val_accuracy: 0.8966 - val_precision: 0.9655 - val_recall: 0.4828\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4406 - accuracy: 0.8214 - precision: 0.9922 - recall: 0.4855 - val_loss: 0.4205 - val_accuracy: 0.8966 - val_precision: 0.9655 - val_recall: 0.5185\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4281 - accuracy: 0.8482 - precision: 0.9609 - recall: 0.4922 - val_loss: 0.3718 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5370\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3822 - accuracy: 0.8571 - precision: 0.9531 - recall: 0.4713 - val_loss: 0.3655 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.4746\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3949 - accuracy: 0.8393 - precision: 0.9844 - recall: 0.4871 - val_loss: 0.3975 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5686\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4510 - accuracy: 0.8036 - precision: 0.9453 - recall: 0.4870 - val_loss: 0.3913 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4045 - accuracy: 0.8393 - precision: 0.9688 - recall: 0.4866 - val_loss: 0.3692 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5091\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3673 - accuracy: 0.8393 - precision: 0.9688 - recall: 0.4891 - val_loss: 0.4110 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5091\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3868 - accuracy: 0.8482 - precision: 0.9531 - recall: 0.4936 - val_loss: 0.3810 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3794 - accuracy: 0.8214 - precision: 0.9766 - recall: 0.4884 - val_loss: 0.3878 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5472\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3880 - accuracy: 0.8661 - precision: 0.9688 - recall: 0.4865 - val_loss: 0.3998 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3765 - accuracy: 0.8571 - precision: 0.9766 - recall: 0.4813 - val_loss: 0.3812 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5179\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3830 - accuracy: 0.8393 - precision: 0.9766 - recall: 0.4851 - val_loss: 0.3958 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5370\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3723 - accuracy: 0.8393 - precision: 0.9766 - recall: 0.4981 - val_loss: 0.3726 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5091\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3679 - accuracy: 0.8393 - precision: 0.9844 - recall: 0.4869 - val_loss: 0.4585 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5091\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.8571 - precision: 0.9688 - recall: 0.4885 - val_loss: 0.3800 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5370\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3869 - accuracy: 0.8393 - precision: 0.9766 - recall: 0.4962 - val_loss: 0.4020 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5385\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3619 - accuracy: 0.8661 - precision: 0.9766 - recall: 0.4766 - val_loss: 0.3802 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3661 - accuracy: 0.8571 - precision: 0.9766 - recall: 0.4799 - val_loss: 0.3874 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5370\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3631 - accuracy: 0.8482 - precision: 0.9688 - recall: 0.4828 - val_loss: 0.3988 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5370\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.8571 - precision: 0.9766 - recall: 0.4943 - val_loss: 0.3792 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5370\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3590 - accuracy: 0.8661 - precision: 0.9766 - recall: 0.4829 - val_loss: 0.3847 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3771 - accuracy: 0.8304 - precision: 0.9766 - recall: 0.4852 - val_loss: 0.3846 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5273\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3803 - accuracy: 0.8036 - precision: 0.9844 - recall: 0.4926 - val_loss: 0.4113 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5185\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4376 - accuracy: 0.8571 - precision: 0.9688 - recall: 0.4789 - val_loss: 0.3725 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4321 - accuracy: 0.8214 - precision: 0.9922 - recall: 0.4673 - val_loss: 0.4104 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5091\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6075 - accuracy: 0.7768 - precision: 0.9375 - recall: 0.4713 - val_loss: 0.4122 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5179\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5598 - accuracy: 0.7946 - precision: 0.9297 - recall: 0.4399 - val_loss: 0.4217 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4667\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4779 - accuracy: 0.8125 - precision: 0.9609 - recall: 0.4755 - val_loss: 0.4347 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5185\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4168 - accuracy: 0.8393 - precision: 0.9844 - recall: 0.4887 - val_loss: 0.3932 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3857 - accuracy: 0.8750 - precision: 0.9766 - recall: 0.4867 - val_loss: 0.4720 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5091\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3705 - accuracy: 0.8661 - precision: 0.9688 - recall: 0.4884 - val_loss: 0.4041 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5000\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4029 - accuracy: 0.8214 - precision: 0.9688 - recall: 0.4856 - val_loss: 0.4107 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5370\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3715 - accuracy: 0.8839 - precision: 0.9688 - recall: 0.4903 - val_loss: 0.4021 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4746\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3634 - accuracy: 0.8482 - precision: 0.9766 - recall: 0.4726 - val_loss: 0.3778 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.4746\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3669 - accuracy: 0.8393 - precision: 0.9844 - recall: 0.4758 - val_loss: 0.4017 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5370\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3619 - accuracy: 0.8482 - precision: 0.9688 - recall: 0.4944 - val_loss: 0.4020 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5370\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3644 - accuracy: 0.8393 - precision: 0.9766 - recall: 0.4853 - val_loss: 0.3692 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3734 - accuracy: 0.8214 - precision: 0.9844 - recall: 0.4707 - val_loss: 0.3906 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5472\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3904 - accuracy: 0.8482 - precision: 0.9609 - recall: 0.4818 - val_loss: 0.4180 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5091\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3610 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4795 - val_loss: 0.3747 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3899 - accuracy: 0.8571 - precision: 0.9844 - recall: 0.4797 - val_loss: 0.4212 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5091\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3737 - accuracy: 0.8571 - precision: 0.9766 - recall: 0.4904 - val_loss: 0.3923 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3636 - accuracy: 0.8482 - precision: 0.9766 - recall: 0.4850 - val_loss: 0.3868 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5273\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3499 - accuracy: 0.8750 - precision: 0.9766 - recall: 0.4764 - val_loss: 0.3889 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3617 - accuracy: 0.8304 - precision: 0.9766 - recall: 0.4655 - val_loss: 0.3890 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3712 - accuracy: 0.8482 - precision: 0.9688 - recall: 0.4864 - val_loss: 0.4323 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5273\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3656 - accuracy: 0.8571 - precision: 0.9844 - recall: 0.4889 - val_loss: 0.3698 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3536 - accuracy: 0.8393 - precision: 0.9766 - recall: 0.4718 - val_loss: 0.4029 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5185\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3502 - accuracy: 0.8750 - precision: 0.9844 - recall: 0.4773 - val_loss: 0.3863 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3523 - accuracy: 0.8571 - precision: 0.9922 - recall: 0.4786 - val_loss: 0.4076 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4912\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3638 - accuracy: 0.8750 - precision: 0.9844 - recall: 0.4759 - val_loss: 0.3936 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3429 - accuracy: 0.8393 - precision: 0.9922 - recall: 0.4777 - val_loss: 0.3856 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3551 - accuracy: 0.8571 - precision: 0.9766 - recall: 0.4710 - val_loss: 0.4052 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4912\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3546 - accuracy: 0.8839 - precision: 0.9844 - recall: 0.4837 - val_loss: 0.3758 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3593 - accuracy: 0.8393 - precision: 0.9688 - recall: 0.4666 - val_loss: 0.3693 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3921 - accuracy: 0.8393 - precision: 0.9688 - recall: 0.4739 - val_loss: 0.4045 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5179\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4122 - accuracy: 0.8750 - precision: 0.9609 - recall: 0.4814 - val_loss: 0.4110 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4516\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4184 - accuracy: 0.7946 - precision: 0.9844 - recall: 0.4634 - val_loss: 0.3739 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3599 - accuracy: 0.8929 - precision: 0.9844 - recall: 0.4811 - val_loss: 0.4851 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.5000\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3884 - accuracy: 0.8661 - precision: 0.9688 - recall: 0.4588 - val_loss: 0.4306 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4516\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.8304 - precision: 0.9609 - recall: 0.4609 - val_loss: 0.4598 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.5000\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3671 - accuracy: 0.8571 - precision: 0.9688 - recall: 0.4922 - val_loss: 0.4376 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4912\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3866 - accuracy: 0.8125 - precision: 0.9922 - recall: 0.4631 - val_loss: 0.3920 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4590\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3673 - accuracy: 0.8839 - precision: 0.9766 - recall: 0.4741 - val_loss: 0.3927 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3639 - accuracy: 0.8393 - precision: 0.9844 - recall: 0.4803 - val_loss: 0.3830 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3385 - accuracy: 0.8482 - precision: 0.9844 - recall: 0.4809 - val_loss: 0.4206 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4828\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3634 - accuracy: 0.8393 - precision: 0.9844 - recall: 0.4815 - val_loss: 0.3811 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3361 - accuracy: 0.8482 - precision: 0.9844 - recall: 0.4829 - val_loss: 0.3852 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5370\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3517 - accuracy: 0.8482 - precision: 0.9844 - recall: 0.4832 - val_loss: 0.3624 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3329 - accuracy: 0.8482 - precision: 0.9844 - recall: 0.4758 - val_loss: 0.3820 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5179\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3348 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4856 - val_loss: 0.3782 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5273\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3286 - accuracy: 0.8571 - precision: 0.9844 - recall: 0.4848 - val_loss: 0.3861 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4915\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3278 - accuracy: 0.8661 - precision: 0.9766 - recall: 0.4797 - val_loss: 0.3794 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3349 - accuracy: 0.8571 - precision: 0.9922 - recall: 0.4774 - val_loss: 0.3847 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3419 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4758 - val_loss: 0.4024 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4915\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3664 - accuracy: 0.8482 - precision: 0.9844 - recall: 0.4735 - val_loss: 0.3823 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3554 - accuracy: 0.8571 - precision: 0.9688 - recall: 0.4714 - val_loss: 0.3874 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3691 - accuracy: 0.8393 - precision: 0.9922 - recall: 0.4674 - val_loss: 0.3687 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3383 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4827 - val_loss: 0.4128 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4667\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3610 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4699 - val_loss: 0.3669 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3464 - accuracy: 0.8482 - precision: 0.9922 - recall: 0.4672 - val_loss: 0.3807 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5179\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3214 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4850 - val_loss: 0.4025 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3337 - accuracy: 0.8750 - precision: 0.9766 - recall: 0.4904 - val_loss: 0.3905 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5179\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3367 - accuracy: 0.8393 - precision: 0.9844 - recall: 0.4775 - val_loss: 0.3820 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3552 - accuracy: 0.8482 - precision: 0.9844 - recall: 0.4717 - val_loss: 0.3826 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3262 - accuracy: 0.8750 - precision: 0.9766 - recall: 0.4813 - val_loss: 0.3927 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3467 - accuracy: 0.8750 - precision: 0.9844 - recall: 0.4764 - val_loss: 0.3911 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3532 - accuracy: 0.8750 - precision: 0.9922 - recall: 0.4656 - val_loss: 0.4395 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3567 - accuracy: 0.8929 - precision: 0.9766 - recall: 0.4754 - val_loss: 0.3664 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3386 - accuracy: 0.8482 - precision: 0.9844 - recall: 0.4905 - val_loss: 0.3624 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3342 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4641 - val_loss: 0.3659 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3088 - accuracy: 0.8661 - precision: 0.9766 - recall: 0.4722 - val_loss: 0.4097 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3442 - accuracy: 0.8482 - precision: 0.9922 - recall: 0.4869 - val_loss: 0.3817 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3136 - accuracy: 0.8750 - precision: 0.9922 - recall: 0.4905 - val_loss: 0.3838 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3268 - accuracy: 0.8929 - precision: 0.9844 - recall: 0.4846 - val_loss: 0.3511 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3328 - accuracy: 0.8482 - precision: 0.9922 - recall: 0.4736 - val_loss: 0.3667 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3123 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4868 - val_loss: 0.3865 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3140 - accuracy: 0.8661 - precision: 0.9922 - recall: 0.4788 - val_loss: 0.3698 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3147 - accuracy: 0.8571 - precision: 0.9766 - recall: 0.4806 - val_loss: 0.3726 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3088 - accuracy: 0.8661 - precision: 0.9922 - recall: 0.4932 - val_loss: 0.3607 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3111 - accuracy: 0.8571 - precision: 0.9922 - recall: 0.4776 - val_loss: 0.3791 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3241 - accuracy: 0.9107 - precision: 0.9766 - recall: 0.4847 - val_loss: 0.3713 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4915\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3281 - accuracy: 0.8750 - precision: 0.9922 - recall: 0.4688 - val_loss: 0.3517 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3236 - accuracy: 0.8750 - precision: 0.9844 - recall: 0.4833 - val_loss: 0.3662 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3302 - accuracy: 0.8661 - precision: 0.9766 - recall: 0.4850 - val_loss: 0.3881 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4915\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3105 - accuracy: 0.8661 - precision: 1.0000 - recall: 0.4798 - val_loss: 0.3840 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3232 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4831 - val_loss: 0.3792 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4915\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3200 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4795 - val_loss: 0.3599 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3488 - accuracy: 0.8571 - precision: 0.9766 - recall: 0.4712 - val_loss: 0.3833 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3045 - accuracy: 0.8750 - precision: 0.9922 - recall: 0.4710 - val_loss: 0.4335 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3691 - accuracy: 0.8393 - precision: 0.9609 - recall: 0.4811 - val_loss: 0.3805 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3517 - accuracy: 0.8482 - precision: 1.0000 - recall: 0.4675 - val_loss: 0.3855 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3169 - accuracy: 0.8839 - precision: 0.9766 - recall: 0.4829 - val_loss: 0.4208 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3207 - accuracy: 0.8839 - precision: 0.9922 - recall: 0.4746 - val_loss: 0.3884 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3046 - accuracy: 0.8482 - precision: 1.0000 - recall: 0.4682 - val_loss: 0.4104 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8929 - precision: 0.9688 - recall: 0.4698 - val_loss: 0.3839 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4812 - accuracy: 0.7946 - precision: 0.9766 - recall: 0.4549 - val_loss: 0.4198 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4667\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4291 - accuracy: 0.8571 - precision: 0.9766 - recall: 0.4708 - val_loss: 0.3893 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3680 - accuracy: 0.8482 - precision: 0.9844 - recall: 0.4736 - val_loss: 0.3846 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3117 - accuracy: 0.8750 - precision: 0.9844 - recall: 0.4841 - val_loss: 0.4124 - val_accuracy: 0.8276 - val_precision: 0.9655 - val_recall: 0.4590\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3566 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4487 - val_loss: 0.3875 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3461 - accuracy: 0.8571 - precision: 0.9531 - recall: 0.4841 - val_loss: 0.4177 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3216 - accuracy: 0.8750 - precision: 0.9922 - recall: 0.4598 - val_loss: 0.3827 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4531\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3233 - accuracy: 0.8571 - precision: 0.9922 - recall: 0.4710 - val_loss: 0.4192 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3306 - accuracy: 0.8571 - precision: 0.9922 - recall: 0.4950 - val_loss: 0.3870 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2980 - accuracy: 0.8929 - precision: 0.9922 - recall: 0.4653 - val_loss: 0.3967 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3360 - accuracy: 0.8929 - precision: 0.9688 - recall: 0.4697 - val_loss: 0.3957 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3249 - accuracy: 0.8661 - precision: 1.0000 - recall: 0.4727 - val_loss: 0.3874 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8661 - precision: 0.9922 - recall: 0.4678 - val_loss: 0.4013 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3144 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4668 - val_loss: 0.3933 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2999 - accuracy: 0.8839 - precision: 1.0000 - recall: 0.4844 - val_loss: 0.3979 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3035 - accuracy: 0.8929 - precision: 0.9766 - recall: 0.4654 - val_loss: 0.3720 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3132 - accuracy: 0.8839 - precision: 1.0000 - recall: 0.4640 - val_loss: 0.3944 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2901 - accuracy: 0.9018 - precision: 1.0000 - recall: 0.4839 - val_loss: 0.3893 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3056 - accuracy: 0.8929 - precision: 0.9844 - recall: 0.4761 - val_loss: 0.3683 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3207 - accuracy: 0.8839 - precision: 0.9844 - recall: 0.4569 - val_loss: 0.3653 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4915\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8839 - precision: 0.9844 - recall: 0.4656 - val_loss: 0.3743 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2921 - accuracy: 0.8750 - precision: 0.9922 - recall: 0.4533 - val_loss: 0.4028 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3053 - accuracy: 0.8750 - precision: 1.0000 - recall: 0.4639 - val_loss: 0.3781 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3039 - accuracy: 0.9018 - precision: 0.9844 - recall: 0.4782 - val_loss: 0.3571 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3202 - accuracy: 0.9018 - precision: 1.0000 - recall: 0.4608 - val_loss: 0.3738 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3773 - accuracy: 0.8661 - precision: 0.9688 - recall: 0.4904 - val_loss: 0.3595 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3026 - accuracy: 0.8929 - precision: 1.0000 - recall: 0.4611 - val_loss: 0.3534 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3174 - accuracy: 0.8839 - precision: 0.9766 - recall: 0.4666 - val_loss: 0.3782 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2988 - accuracy: 0.8571 - precision: 1.0000 - recall: 0.4748 - val_loss: 0.3650 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2745 - accuracy: 0.9107 - precision: 1.0000 - recall: 0.4788 - val_loss: 0.3886 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3233 - accuracy: 0.8929 - precision: 0.9766 - recall: 0.4684 - val_loss: 0.3946 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4531\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3160 - accuracy: 0.8750 - precision: 1.0000 - recall: 0.4622 - val_loss: 0.3720 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2925 - accuracy: 0.9018 - precision: 0.9844 - recall: 0.4762 - val_loss: 0.3604 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2824 - accuracy: 0.8839 - precision: 1.0000 - recall: 0.4675 - val_loss: 0.3744 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2848 - accuracy: 0.8929 - precision: 0.9844 - recall: 0.4758 - val_loss: 0.3837 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2815 - accuracy: 0.9018 - precision: 1.0000 - recall: 0.4781 - val_loss: 0.3711 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2710 - accuracy: 0.8750 - precision: 1.0000 - recall: 0.4724 - val_loss: 0.3776 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3311 - accuracy: 0.8750 - precision: 0.9688 - recall: 0.4808 - val_loss: 0.3682 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3557 - accuracy: 0.8661 - precision: 0.9844 - recall: 0.4350 - val_loss: 0.3833 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3734 - accuracy: 0.8571 - precision: 0.9609 - recall: 0.4768 - val_loss: 0.4109 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3043 - accuracy: 0.8839 - precision: 1.0000 - recall: 0.4643 - val_loss: 0.3854 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3115 - accuracy: 0.8929 - precision: 0.9844 - recall: 0.4726 - val_loss: 0.3949 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2771 - accuracy: 0.9107 - precision: 1.0000 - recall: 0.4813 - val_loss: 0.3782 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2714 - accuracy: 0.9196 - precision: 0.9922 - recall: 0.4759 - val_loss: 0.3837 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2745 - accuracy: 0.9107 - precision: 0.9844 - recall: 0.4711 - val_loss: 0.3837 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3074 - accuracy: 0.8661 - precision: 1.0000 - recall: 0.4665 - val_loss: 0.3948 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2902 - accuracy: 0.8929 - precision: 0.9766 - recall: 0.4724 - val_loss: 0.3742 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2927 - accuracy: 0.8839 - precision: 1.0000 - recall: 0.4595 - val_loss: 0.3625 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2779 - accuracy: 0.9107 - precision: 0.9844 - recall: 0.4686 - val_loss: 0.3779 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3090 - accuracy: 0.8661 - precision: 0.9922 - recall: 0.4723 - val_loss: 0.3717 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2805 - accuracy: 0.9107 - precision: 0.9922 - recall: 0.4688 - val_loss: 0.3759 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2900 - accuracy: 0.8929 - precision: 0.9922 - recall: 0.4636 - val_loss: 0.3874 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2869 - accuracy: 0.8839 - precision: 0.9844 - recall: 0.4774 - val_loss: 0.3785 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2917 - accuracy: 0.8839 - precision: 0.9844 - recall: 0.4643 - val_loss: 0.3994 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4531\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3302 - accuracy: 0.8482 - precision: 1.0000 - recall: 0.4463 - val_loss: 0.3732 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3267 - accuracy: 0.8929 - precision: 0.9766 - recall: 0.4809 - val_loss: 0.3656 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2803 - accuracy: 0.8929 - precision: 1.0000 - recall: 0.4730 - val_loss: 0.3767 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2649 - accuracy: 0.8929 - precision: 1.0000 - recall: 0.4762 - val_loss: 0.3752 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2760 - accuracy: 0.9018 - precision: 0.9844 - recall: 0.4848 - val_loss: 0.3705 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2621 - accuracy: 0.9107 - precision: 1.0000 - recall: 0.4635 - val_loss: 0.3780 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4531\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2991 - accuracy: 0.9018 - precision: 0.9922 - recall: 0.4588 - val_loss: 0.3717 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2627 - accuracy: 0.9018 - precision: 0.9922 - recall: 0.4816 - val_loss: 0.3994 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2630 - accuracy: 0.9018 - precision: 0.9844 - recall: 0.4743 - val_loss: 0.3789 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2651 - accuracy: 0.8929 - precision: 1.0000 - recall: 0.4760 - val_loss: 0.4193 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2836 - accuracy: 0.9107 - precision: 0.9922 - recall: 0.4832 - val_loss: 0.3770 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2775 - accuracy: 0.8929 - precision: 0.9922 - recall: 0.4672 - val_loss: 0.3623 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2826 - accuracy: 0.8839 - precision: 1.0000 - recall: 0.4799 - val_loss: 0.3947 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4915\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2803 - accuracy: 0.8839 - precision: 1.0000 - recall: 0.4665 - val_loss: 0.3535 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4462\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2778 - accuracy: 0.9018 - precision: 0.9922 - recall: 0.4587 - val_loss: 0.3679 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2836 - accuracy: 0.9018 - precision: 0.9922 - recall: 0.4674 - val_loss: 0.3992 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3179 - accuracy: 0.9107 - precision: 0.9922 - recall: 0.4933 - val_loss: 0.3508 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4531\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3044 - accuracy: 0.9018 - precision: 1.0000 - recall: 0.4533 - val_loss: 0.3379 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4531\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.9018 - precision: 0.9844 - recall: 0.4686 - val_loss: 0.4016 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3306 - accuracy: 0.8839 - precision: 1.0000 - recall: 0.4549 - val_loss: 0.3756 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2922 - accuracy: 0.9107 - precision: 0.9844 - recall: 0.4721 - val_loss: 0.4380 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5088\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2699 - accuracy: 0.9018 - precision: 1.0000 - recall: 0.4871 - val_loss: 0.3631 - val_accuracy: 0.8966 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3194 - accuracy: 0.8750 - precision: 1.0000 - recall: 0.4436 - val_loss: 0.3654 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2678 - accuracy: 0.9196 - precision: 0.9766 - recall: 0.4764 - val_loss: 0.4821 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2911 - accuracy: 0.8839 - precision: 0.9922 - recall: 0.4803 - val_loss: 0.3814 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2851 - accuracy: 0.9018 - precision: 0.9922 - recall: 0.4430 - val_loss: 0.3683 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2963 - accuracy: 0.9107 - precision: 0.9922 - recall: 0.4796 - val_loss: 0.4845 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4915\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2798 - accuracy: 0.9107 - precision: 1.0000 - recall: 0.4738 - val_loss: 0.3935 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2942 - accuracy: 0.8929 - precision: 0.9922 - recall: 0.4489 - val_loss: 0.3943 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2648 - accuracy: 0.9018 - precision: 1.0000 - recall: 0.4707 - val_loss: 0.4014 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2637 - accuracy: 0.9196 - precision: 0.9922 - recall: 0.4698 - val_loss: 0.4045 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2508 - accuracy: 0.9464 - precision: 1.0000 - recall: 0.4780 - val_loss: 0.3839 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4754\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3031 - accuracy: 0.9018 - precision: 0.9766 - recall: 0.4816 - val_loss: 0.3901 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2778 - accuracy: 0.9018 - precision: 1.0000 - recall: 0.4623 - val_loss: 0.3703 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2753 - accuracy: 0.9196 - precision: 0.9844 - recall: 0.4754 - val_loss: 0.3847 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2765 - accuracy: 0.8929 - precision: 1.0000 - recall: 0.4646 - val_loss: 0.3670 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3098 - accuracy: 0.9018 - precision: 0.9844 - recall: 0.4536 - val_loss: 0.3610 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2684 - accuracy: 0.9018 - precision: 0.9922 - recall: 0.4751 - val_loss: 0.4667 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4915\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2714 - accuracy: 0.9107 - precision: 1.0000 - recall: 0.4807 - val_loss: 0.3714 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2886 - accuracy: 0.9018 - precision: 0.9844 - recall: 0.4671 - val_loss: 0.3860 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4531\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2742 - accuracy: 0.8750 - precision: 1.0000 - recall: 0.4629 - val_loss: 0.3829 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2729 - accuracy: 0.8929 - precision: 0.9922 - recall: 0.4744 - val_loss: 0.3675 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2737 - accuracy: 0.9107 - precision: 1.0000 - recall: 0.4411 - val_loss: 0.3563 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4677\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2761 - accuracy: 0.9107 - precision: 0.9844 - recall: 0.4822 - val_loss: 0.4425 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4833\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2911 - accuracy: 0.8482 - precision: 0.9922 - recall: 0.4591 - val_loss: 0.3697 - val_accuracy: 0.8276 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3066 - accuracy: 0.8929 - precision: 0.9844 - recall: 0.4642 - val_loss: 0.4048 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3388 - accuracy: 0.8482 - precision: 0.9844 - recall: 0.4585 - val_loss: 0.4268 - val_accuracy: 0.8621 - val_precision: 0.9655 - val_recall: 0.4667\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3292 - accuracy: 0.8750 - precision: 0.9844 - recall: 0.4742 - val_loss: 0.3616 - val_accuracy: 0.8621 - val_precision: 1.0000 - val_recall: 0.4603\n"
     ]
    }
   ],
   "source": [
    "max_len = X_train.shape[1]\n",
    "\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = nn_model(max_len)\n",
    "history = check_model(model, X_train, y_train, X_test, y_test, EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2337c77a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "2337c77a",
    "outputId": "2b651ba5-c64d-496b-d9c0-3ac96df44e96",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.319387</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.370695</td>\n",
       "      <td>1.227196</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.396552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.218782</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>1.157516</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.396552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.185793</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.386719</td>\n",
       "      <td>1.127947</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.396552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.167144</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.386719</td>\n",
       "      <td>1.096605</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.396552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.129654</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>1.059723</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.403509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>0.276102</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.482212</td>\n",
       "      <td>0.442523</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>0.291141</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.459100</td>\n",
       "      <td>0.369672</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.464240</td>\n",
       "      <td>0.404816</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>0.338849</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.458451</td>\n",
       "      <td>0.426798</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>0.329154</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.474188</td>\n",
       "      <td>0.361612</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch      loss  accuracy  precision    recall  val_loss  val_accuracy  \\\n",
       "0        1  1.319387  0.321429   0.703125  0.370695  1.227196      0.482759   \n",
       "1        2  1.218782  0.508929   0.781250  0.390625  1.157516      0.586207   \n",
       "2        3  1.185793  0.571429   0.773438  0.386719  1.127947      0.620690   \n",
       "3        4  1.167144  0.580357   0.773438  0.386719  1.096605      0.620690   \n",
       "4        5  1.129654  0.589286   0.781250  0.390625  1.059723      0.620690   \n",
       "..     ...       ...       ...        ...       ...       ...           ...   \n",
       "495    496  0.276102  0.910714   0.984375  0.482212  0.442523      0.862069   \n",
       "496    497  0.291141  0.848214   0.992188  0.459100  0.369672      0.827586   \n",
       "497    498  0.306616  0.892857   0.984375  0.464240  0.404816      0.862069   \n",
       "498    499  0.338849  0.848214   0.984375  0.458451  0.426798      0.862069   \n",
       "499    500  0.329154  0.875000   0.984375  0.474188  0.361612      0.862069   \n",
       "\n",
       "     val_precision  val_recall  \n",
       "0         0.793103    0.396552  \n",
       "1         0.793103    0.396552  \n",
       "2         0.793103    0.396552  \n",
       "3         0.793103    0.396552  \n",
       "4         0.793103    0.403509  \n",
       "..             ...         ...  \n",
       "495       1.000000    0.483333  \n",
       "496       1.000000    0.460317  \n",
       "497       1.000000    0.460317  \n",
       "498       0.965517    0.466667  \n",
       "499       1.000000    0.460317  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df['epoch'] = hist_df.index + 1\n",
    "cols = list(hist_df.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "hist_df = hist_df[cols]\n",
    "hist_df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "112ff3c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "112ff3c1",
    "outputId": "fbaf9a9e-7ca5-44b2-f434-a0df39e7438d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>470</td>\n",
       "      <td>0.304375</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.453276</td>\n",
       "      <td>0.337856</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.453125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch      loss  accuracy  precision    recall  val_loss  val_accuracy  \\\n",
       "469    470  0.304375  0.901786        1.0  0.453276  0.337856      0.896552   \n",
       "\n",
       "     val_precision  val_recall  \n",
       "469            1.0    0.453125  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_of_best_model = hist_df[hist_df.val_loss == hist_df.val_loss.min()]\n",
    "values_of_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2605d67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2605d67",
    "outputId": "1c0fbe0d-fa0e-4c8a-dd08-13d747b5b04d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 32)                672       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,828\n",
      "Trainable params: 15,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fb9520c",
   "metadata": {
    "id": "6fb9520c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d50ed9a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d50ed9a3",
    "outputId": "019523de-9b80-48ed-d389-7b09a467e931",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.37e-03 3.36e-01 7.96e-01 9.86e-01]\n",
      " [1.00e+00 8.55e-01 4.49e-07 1.63e-02]\n",
      " [2.26e-03 9.81e-01 9.91e-01 4.53e-04]\n",
      " [2.05e-03 9.52e-01 9.85e-01 5.23e-03]\n",
      " [9.06e-01 6.99e-01 1.57e-01 2.56e-02]\n",
      " [0.00e+00 1.00e+00 1.00e+00 3.63e-33]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.51e-38]\n",
      " [9.95e-01 9.45e-01 6.93e-09 1.65e-01]\n",
      " [0.00e+00 1.00e+00 1.00e+00 2.29e-31]\n",
      " [9.95e-01 9.45e-01 6.93e-09 1.65e-01]\n",
      " [4.62e-01 9.17e-01 3.55e-06 8.91e-01]\n",
      " [1.35e-09 1.00e+00 9.99e-01 3.95e-03]\n",
      " [9.86e-01 6.56e-01 1.74e-05 7.26e-01]\n",
      " [9.83e-01 4.53e-01 5.31e-04 6.94e-01]\n",
      " [9.83e-01 4.53e-01 5.31e-04 6.94e-01]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.50e-30]\n",
      " [3.79e-10 1.00e+00 1.00e+00 5.41e-06]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.73e-25]\n",
      " [9.96e-01 9.52e-01 9.30e-03 3.88e-04]\n",
      " [9.93e-01 7.45e-01 3.24e-06 4.81e-01]\n",
      " [2.37e-03 3.36e-01 7.96e-01 9.86e-01]\n",
      " [9.92e-01 9.62e-01 1.87e-09 1.82e-01]\n",
      " [9.59e-01 7.09e-01 1.92e-05 7.04e-01]\n",
      " [9.88e-01 6.62e-01 1.51e-05 6.98e-01]\n",
      " [5.12e-10 1.00e+00 1.00e+00 8.78e-03]\n",
      " [9.99e-01 9.76e-01 2.46e-10 7.65e-03]\n",
      " [8.38e-04 5.10e-01 9.78e-01 8.63e-01]\n",
      " [9.95e-01 6.76e-01 1.04e-05 3.83e-01]\n",
      " [9.39e-01 7.42e-01 6.36e-06 9.38e-01]]\n"
     ]
    }
   ],
   "source": [
    " # predict test data\n",
    "y_pred= model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46925a36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46925a36",
    "outputId": "53081a7d-397f-48d3-cd03-5666c93aa616",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9858576,\n",
       " 0.9995787,\n",
       " 0.99057907,\n",
       " 0.98543614,\n",
       " 0.90620375,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9951972,\n",
       " 1.0,\n",
       " 0.9951972,\n",
       " 0.91676766,\n",
       " 0.99987346,\n",
       " 0.9862865,\n",
       " 0.98279035,\n",
       " 0.98279035,\n",
       " 1.0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = []\n",
    "for i in range(0, 16):\n",
    "    predict.append(max(y_pred[i]))\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51844188",
   "metadata": {
    "id": "51844188",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4864b62d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "4864b62d",
    "outputId": "1570b09a-26d0-444c-f053-95bcccee3477",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=['Normal', 'RS', 'MAS', 'WS'],\n",
    "                      normalize=False,\n",
    "                      title='Confusion matrix, with normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8b9a523",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8b9a523",
    "outputId": "17dd06ce-1796-4c1d-b872-53d380e3399a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.87      1.00      0.93        13\n",
      "          RS       0.89      0.80      0.84        10\n",
      "         MAS       0.67      0.67      0.67         3\n",
      "          WS       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.86        29\n",
      "   macro avg       0.86      0.78      0.81        29\n",
      "weighted avg       0.87      0.86      0.86        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1),\n",
    "                            y_pred.argmax(axis=1),\n",
    "                            target_names=['Normal', 'RS', 'MAS', 'WS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a43e7bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "6a43e7bc",
    "outputId": "33797b44-72a1-4905-b651-be0cd59796b9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Energy_0</th>\n",
       "      <th>Corr_0</th>\n",
       "      <th>Homogen_0</th>\n",
       "      <th>Contrast_0</th>\n",
       "      <th>ASM_0</th>\n",
       "      <th>Energy_45</th>\n",
       "      <th>Corr_45</th>\n",
       "      <th>Homogen_45</th>\n",
       "      <th>Contrast_45</th>\n",
       "      <th>...</th>\n",
       "      <th>Homogen_90</th>\n",
       "      <th>Contrast_90</th>\n",
       "      <th>ASM_90</th>\n",
       "      <th>Energy_135</th>\n",
       "      <th>Corr_135</th>\n",
       "      <th>Homogen_135</th>\n",
       "      <th>Contrast_135</th>\n",
       "      <th>ASM_135</th>\n",
       "      <th>output</th>\n",
       "      <th>filenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.238833</td>\n",
       "      <td>0.517603</td>\n",
       "      <td>0.412533</td>\n",
       "      <td>3069.396847</td>\n",
       "      <td>0.057041</td>\n",
       "      <td>0.232840</td>\n",
       "      <td>0.481561</td>\n",
       "      <td>0.384189</td>\n",
       "      <td>3294.214195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379124</td>\n",
       "      <td>3528.956028</td>\n",
       "      <td>0.057041</td>\n",
       "      <td>0.242723</td>\n",
       "      <td>0.514698</td>\n",
       "      <td>0.431989</td>\n",
       "      <td>3083.943518</td>\n",
       "      <td>0.057041</td>\n",
       "      <td>0</td>\n",
       "      <td>dataset/0/fish_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.238353</td>\n",
       "      <td>0.512358</td>\n",
       "      <td>0.413436</td>\n",
       "      <td>3262.862123</td>\n",
       "      <td>0.056812</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>0.525515</td>\n",
       "      <td>0.433085</td>\n",
       "      <td>3173.205623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367355</td>\n",
       "      <td>3774.753721</td>\n",
       "      <td>0.056812</td>\n",
       "      <td>0.230253</td>\n",
       "      <td>0.464397</td>\n",
       "      <td>0.376618</td>\n",
       "      <td>3582.181970</td>\n",
       "      <td>0.056812</td>\n",
       "      <td>0</td>\n",
       "      <td>dataset/0/fish_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.259169</td>\n",
       "      <td>0.445380</td>\n",
       "      <td>0.457163</td>\n",
       "      <td>3189.128320</td>\n",
       "      <td>0.067168</td>\n",
       "      <td>0.262902</td>\n",
       "      <td>0.466383</td>\n",
       "      <td>0.471457</td>\n",
       "      <td>3070.517608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523060</td>\n",
       "      <td>2503.627934</td>\n",
       "      <td>0.067168</td>\n",
       "      <td>0.263560</td>\n",
       "      <td>0.471281</td>\n",
       "      <td>0.475134</td>\n",
       "      <td>3042.272336</td>\n",
       "      <td>0.067168</td>\n",
       "      <td>0</td>\n",
       "      <td>dataset/0/fish_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.269625</td>\n",
       "      <td>0.548643</td>\n",
       "      <td>0.496141</td>\n",
       "      <td>3177.300241</td>\n",
       "      <td>0.072697</td>\n",
       "      <td>0.252457</td>\n",
       "      <td>0.419631</td>\n",
       "      <td>0.438557</td>\n",
       "      <td>4074.419555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421847</td>\n",
       "      <td>4255.804873</td>\n",
       "      <td>0.072697</td>\n",
       "      <td>0.251784</td>\n",
       "      <td>0.413907</td>\n",
       "      <td>0.434164</td>\n",
       "      <td>4114.603695</td>\n",
       "      <td>0.072697</td>\n",
       "      <td>0</td>\n",
       "      <td>dataset/0/fish_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.262031</td>\n",
       "      <td>0.443838</td>\n",
       "      <td>0.461995</td>\n",
       "      <td>3248.030262</td>\n",
       "      <td>0.068660</td>\n",
       "      <td>0.266288</td>\n",
       "      <td>0.473357</td>\n",
       "      <td>0.478816</td>\n",
       "      <td>3078.603990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577084</td>\n",
       "      <td>2064.272280</td>\n",
       "      <td>0.068660</td>\n",
       "      <td>0.269411</td>\n",
       "      <td>0.490361</td>\n",
       "      <td>0.489698</td>\n",
       "      <td>2979.088552</td>\n",
       "      <td>0.068660</td>\n",
       "      <td>0</td>\n",
       "      <td>dataset/0/fish_6.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Energy_0    Corr_0  Homogen_0   Contrast_0     ASM_0  \\\n",
       "0           0  0.238833  0.517603   0.412533  3069.396847  0.057041   \n",
       "1           0  0.238353  0.512358   0.413436  3262.862123  0.056812   \n",
       "2           0  0.259169  0.445380   0.457163  3189.128320  0.067168   \n",
       "3           0  0.269625  0.548643   0.496141  3177.300241  0.072697   \n",
       "4           0  0.262031  0.443838   0.461995  3248.030262  0.068660   \n",
       "\n",
       "   Energy_45   Corr_45  Homogen_45  Contrast_45  ...  Homogen_90  Contrast_90  \\\n",
       "0   0.232840  0.481561    0.384189  3294.214195  ...    0.379124  3528.956028   \n",
       "1   0.242940  0.525515    0.433085  3173.205623  ...    0.367355  3774.753721   \n",
       "2   0.262902  0.466383    0.471457  3070.517608  ...    0.523060  2503.627934   \n",
       "3   0.252457  0.419631    0.438557  4074.419555  ...    0.421847  4255.804873   \n",
       "4   0.266288  0.473357    0.478816  3078.603990  ...    0.577084  2064.272280   \n",
       "\n",
       "     ASM_90  Energy_135  Corr_135  Homogen_135  Contrast_135   ASM_135  \\\n",
       "0  0.057041    0.242723  0.514698     0.431989   3083.943518  0.057041   \n",
       "1  0.056812    0.230253  0.464397     0.376618   3582.181970  0.056812   \n",
       "2  0.067168    0.263560  0.471281     0.475134   3042.272336  0.067168   \n",
       "3  0.072697    0.251784  0.413907     0.434164   4114.603695  0.072697   \n",
       "4  0.068660    0.269411  0.490361     0.489698   2979.088552  0.068660   \n",
       "\n",
       "   output             filenames  \n",
       "0       0  dataset/0/fish_0.jpg  \n",
       "1       0  dataset/0/fish_1.jpg  \n",
       "2       0  dataset/0/fish_3.jpg  \n",
       "3       0  dataset/0/fish_2.jpg  \n",
       "4       0  dataset/0/fish_6.jpg  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = dt['output']\n",
    "xtest = dt.drop(columns=['Unnamed: 0', 'output', 'filenames'])\n",
    "xtest = preprocessing.StandardScaler().fit(xtest).transform(xtest.astype(float))\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d07d76e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d07d76e2",
    "outputId": "993dcd75-7852-461a-fe8b-b875142253dc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " categorical label : \n",
      " [0 1 2 3]\n",
      "\n",
      "\n",
      " one hot encoding for sample 0 : \n",
      " [1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(dt[\"output\"].values)\n",
    "\n",
    "print(\" categorical label : \\n\", le.classes_)\n",
    "\n",
    "y2 = le.transform(dt['output'].values)\n",
    "y2 = to_categorical(y2)\n",
    "\n",
    "print(\"\\n\\n one hot encoding for sample 0 : \\n\", y2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe2de98e",
   "metadata": {
    "id": "fe2de98e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y2test = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f5b07c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f5b07c3",
    "outputId": "157b98d3-afda-4579-c6ef-d62a3f8cdaf4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82, 20), (82, 4))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape, y2test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "700c388f",
   "metadata": {
    "id": "700c388f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8aa0712",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8aa0712",
    "outputId": "cecfc510-dca8-430f-8e87-4eb6d3d704ef",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.78e-03 1.00e+00 1.16e-26 1.00e+00]\n",
      " [1.44e-01 1.00e+00 1.51e-25 1.00e+00]\n",
      " [1.56e-11 1.00e+00 0.00e+00 1.91e-02]\n",
      " [1.00e+00 1.00e+00 0.00e+00 0.00e+00]\n",
      " [1.81e-13 1.00e+00 1.95e-25 2.54e-01]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.83e-29]\n",
      " [1.70e-02 1.00e+00 0.00e+00 1.31e-08]\n",
      " [4.64e-08 1.00e+00 0.00e+00 1.00e+00]\n",
      " [1.73e-12 1.00e+00 0.00e+00 7.38e-05]\n",
      " [1.00e+00 1.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 7.66e-18]\n",
      " [4.89e-05 1.00e+00 0.00e+00 1.00e+00]\n",
      " [1.00e+00 1.00e+00 1.15e-18 3.47e-21]\n",
      " [1.00e+00 1.00e+00 0.00e+00 1.37e-36]\n",
      " [6.06e-36 1.00e+00 1.11e-04 1.00e+00]\n",
      " [1.00e+00 1.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.00e+00]\n",
      " [1.00e+00 1.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 2.39e-18]\n",
      " [1.24e-34 1.00e+00 1.00e+00 1.69e-37]\n",
      " [1.00e+00 1.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [1.00e+00 1.00e+00 0.00e+00 0.00e+00]\n",
      " [3.30e-37 1.00e+00 7.20e-08 1.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 2.48e-23]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [1.00e+00 1.00e+00 0.00e+00 0.00e+00]\n",
      " [7.84e-34 1.00e+00 1.00e+00 1.70e-30]\n",
      " [1.16e-33 1.00e+00 1.00e+00 3.26e-30]\n",
      " [4.58e-37 1.00e+00 1.00e+00 0.00e+00]\n",
      " [2.23e-30 1.00e+00 1.00e+00 9.31e-02]\n",
      " [1.00e+00 1.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 3.47e-36]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [5.59e-02 1.00e+00 5.76e-16 2.83e-24]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.03e-10]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 8.09e-26]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 2.66e-37]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.06e-27]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 9.40e-12]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.99e-36]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [6.97e-31 9.99e-01 6.89e-06 1.00e+00]\n",
      " [2.54e-16 1.00e+00 0.00e+00 1.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 6.25e-11]\n",
      " [0.00e+00 1.00e+00 1.00e+00 7.50e-31]\n",
      " [0.00e+00 1.00e+00 1.00e+00 2.56e-34]\n",
      " [2.83e-12 1.00e+00 2.01e-05 3.60e-03]\n",
      " [0.00e+00 1.00e+00 1.00e+00 7.81e-29]\n",
      " [0.00e+00 1.00e+00 9.99e-01 1.00e+00]\n",
      " [1.52e-07 1.00e+00 0.00e+00 1.00e+00]\n",
      " [2.44e-14 1.00e+00 1.00e+00 9.15e-04]\n",
      " [4.52e-38 1.00e+00 1.51e-38 1.00e+00]\n",
      " [0.00e+00 1.00e+00 1.02e-04 1.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 2.85e-34]\n",
      " [0.00e+00 1.00e+00 1.00e+00 4.39e-30]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.17e-33]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.42e-14]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.07e-19]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.93e-21]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.64e-35]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 1.37e-22]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 9.79e-19]\n",
      " [0.00e+00 1.00e+00 1.00e+00 8.04e-08]\n",
      " [1.02e-16 1.00e+00 2.05e-01 5.75e-06]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.00e+00 1.00e+00 0.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "ypredict = model.predict(xtest)\n",
    "print(ypredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5221124e",
   "metadata": {
    "id": "5221124e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y2test.argmax(axis=1), ypredict.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b60b90b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "b60b90b4",
    "outputId": "d4f50f01-7cf9-4f2d-9080-a52c5af854cd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=['Normal', 'RS', 'MAS', 'WS'],\n",
    "                      normalize=False,\n",
    "                      title='Confusion matrix, with normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f55e4bfd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f55e4bfd",
    "outputId": "01a0fba5-2afe-4bc2-dbae-b5bf45702940",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.75      0.23      0.35        26\n",
      "          RS       0.33      0.92      0.49        25\n",
      "         MAS       0.00      0.00      0.00        16\n",
      "          WS       0.40      0.13      0.20        15\n",
      "\n",
      "    accuracy                           0.38        82\n",
      "   macro avg       0.37      0.32      0.26        82\n",
      "weighted avg       0.41      0.38      0.30        82\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2test.argmax(axis=1),\n",
    "                            ypredict.argmax(axis=1),\n",
    "                            target_names=['Normal', 'RS', 'MAS', 'WS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "qj4Gj6RGfYQv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qj4Gj6RGfYQv",
    "outputId": "b39475ae-c942-458d-dac3-6f0433338777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in d:\\anaconda\\anaconda3\\lib\\site-packages (3.24.1)\n",
      "Requirement already satisfied: aiohttp in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (3.8.1)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: aiofiles in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: httpx in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (0.23.3)\n",
      "Requirement already satisfied: ffmpy in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: pillow in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (9.0.1)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (3.5.1)\n",
      "Requirement already satisfied: fastapi in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (0.95.0)\n",
      "Requirement already satisfied: uvicorn in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (0.21.1)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: markupsafe in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: gradio-client>=0.0.5 in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (0.0.7)\n",
      "Requirement already satisfied: orjson in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (3.8.9)\n",
      "Requirement already satisfied: pydub in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (1.21.5)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (2.11.3)\n",
      "Requirement already satisfied: python-multipart in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (4.5.0)\n",
      "Requirement already satisfied: pydantic in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (1.10.7)\n",
      "Requirement already satisfied: websockets>=10.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (11.0)\n",
      "Requirement already satisfied: semantic-version in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: altair>=4.2.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio) (4.2.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from altair>=4.2.0->gradio) (4.4.0)\n",
      "Requirement already satisfied: entrypoints in d:\\anaconda\\anaconda3\\lib\\site-packages (from altair>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: toolz in d:\\anaconda\\anaconda3\\lib\\site-packages (from altair>=4.2.0->gradio) (0.11.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio-client>=0.0.5->gradio) (2022.2.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\anaconda3\\lib\\site-packages (from gradio-client>=0.0.5->gradio) (21.3)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.13.0->gradio) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.13.0->gradio) (4.64.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from pandas->gradio) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\anaconda\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (1.6.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from fastapi->gradio) (0.26.1)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from httpx->gradio) (0.16.3)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\anaconda3\\lib\\site-packages (from httpx->gradio) (2021.10.8)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in d:\\anaconda\\anaconda3\\lib\\site-packages (from httpx->gradio) (1.5.0)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda\\anaconda3\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\anaconda3\\lib\\site-packages (from requests->gradio) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from requests->gradio) (1.26.9)\n",
      "Requirement already satisfied: click>=7.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from uvicorn->gradio) (8.0.4)\n",
      "Requirement already satisfied: h11>=0.8 in d:\\anaconda\\anaconda3\\lib\\site-packages (from uvicorn->gradio) (0.14.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn->gradio) (0.4.4)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in d:\\anaconda\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: uc-micro-py in d:\\anaconda\\anaconda3\\lib\\site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\anaconda\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd3ca9a2",
   "metadata": {
    "id": "fd3ca9a2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.feature import greycomatrix, greycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "708539d2",
   "metadata": {
    "id": "708539d2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "    resized = cv2.resize(img, (256, 256), Image.BICUBIC)\n",
    "    bgr = resized[:, :, ::-1].copy()\n",
    "\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    clahe = cv2.createCLAHE(clipLimit=0)\n",
    "    lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
    "    lab[:, :, 1] = clahe.apply(lab[:, :, 1])\n",
    "    lab[:, :, 2] = clahe.apply(lab[:, :, 2])\n",
    "    bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    res = cv2.fastNlMeansDenoisingColored(bgr, None, 10, 10, 1, 3)\n",
    "    #bgr = cv2.bilateralFilter(bgr, 5, 1, 1)\n",
    "    return res\n",
    "\n",
    "\n",
    "def segmentation(img, online=False):\n",
    "    pre = preprocessing(img)\n",
    "    image = cv2.cvtColor(pre, cv2.COLOR_BGR2LAB)\n",
    "    image = image.reshape((256 * 256, 3))\n",
    "\n",
    "    clt = KMeans(n_clusters=5)\n",
    "    labels = clt.fit_predict(image)\n",
    "    quant = clt.cluster_centers_.astype(\"uint8\")[labels]\n",
    "    quant = quant.reshape((256, 256, 3))\n",
    "    res = image.reshape((256, 256, 3))\n",
    "\n",
    "    if online:\n",
    "        return quant\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def gray_segmentation(img):\n",
    "    pre = preprocessing(img)\n",
    "    segmented = segmentation(pre, True)\n",
    "    bgr = cv2.cvtColor(segmented, cv2.COLOR_LAB2BGR)\n",
    "    res = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    return res\n",
    "\n",
    "\n",
    "def extract(img, online=False):\n",
    "    image = gray_segmentation(img)\n",
    "    degs = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]\n",
    "    post = [0, 45, 90, 135]\n",
    "    val = []\n",
    "    for i, deg in enumerate(degs):\n",
    "        GLCM = greycomatrix(image, [3], [deg])\n",
    "        energy = greycoprops(GLCM, 'energy')[0]\n",
    "        corr = greycoprops(GLCM, 'correlation')[0]\n",
    "        hom = greycoprops(GLCM, 'homogeneity')[0]\n",
    "        contr = greycoprops(GLCM, 'contrast')[0]\n",
    "        asm = greycoprops(GLCM, 'ASM')[0]\n",
    "\n",
    "        temp = [post[i], energy[0], corr[0], hom[0], contr[0], asm[0]]\n",
    "        val.append(temp)\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        np.array(val),\n",
    "        columns=['Degree', 'Contrast', 'Energy', 'Korelasi', 'ASM', 'Homogenity'],\n",
    "    )\n",
    "\n",
    "    if online:\n",
    "        return np.array(val)\n",
    "    return res\n",
    "\n",
    "\n",
    "def predict_(img):\n",
    "    feature = extract(img, True)[:, 1:]\n",
    "    # print(feature.shape)\n",
    "    target_names = ['Normal', 'RS', 'MAS', 'WS']\n",
    "    feature = feature.reshape((1, 20))\n",
    "    pred = model.predict(feature)\n",
    "\n",
    "    return target_names[pred.argmax()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5d30b8d",
   "metadata": {
    "id": "a5d30b8d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demo = gr.Blocks()\n",
    "\n",
    "with demo:\n",
    "    gr.Markdown('Step by step Demo')\n",
    "    img_input = gr.Image()\n",
    "    # with gr.Row():\n",
    "    img_preprocess = gr.Image()\n",
    "    button_preprocess = gr.Button('Preprocessing Button')\n",
    "\n",
    "    # with gr.Row():\n",
    "    img_segmentation = gr.Image()\n",
    "    button_segm = gr.Button(\"Segmentation Button\")\n",
    "\n",
    "    # with gr.Row():\n",
    "    img_grayscale = gr.Image()\n",
    "    button_gray = gr.Button(\"RGB to Grayscale Button\")\n",
    "\n",
    "    # with gr.Row():\n",
    "    data = gr.DataFrame(\n",
    "        headers=['Degree', 'Contrast', 'Energy', 'Korelasi', 'ASM', 'Homogenity'],\n",
    "        # row_count=(1, 'fixed')\n",
    "    )\n",
    "    button_extract = gr.Button('Extract Data')\n",
    "\n",
    "    output = gr.Textbox(label=\"Prediction Result\")\n",
    "    button_predict = gr.Button('Predict')\n",
    "    button_preprocess.click(preprocessing, inputs=img_input, outputs=img_preprocess)\n",
    "    button_segm.click(segmentation, inputs=img_input, outputs=img_segmentation)\n",
    "    button_gray.click(gray_segmentation, inputs=img_input, outputs=img_grayscale)\n",
    "    button_extract.click(extract, inputs=img_input, outputs=data)\n",
    "    button_predict.click(predict_, inputs=img_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ad1e9718",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "ad1e9718",
    "outputId": "4cb37104-4707-4bca-fdb4-9906161fa157",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "D:\\Anaconda\\anaconda3\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n"
     ]
    }
   ],
   "source": [
    "demo.close()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea26652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
